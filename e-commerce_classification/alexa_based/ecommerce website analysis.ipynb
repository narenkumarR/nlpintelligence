{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp1 = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/e-commerce_classification/ecom_comps_from_topic_extraction.csv')\n",
    "tmp2 = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/e-commerce_classification/web_crawling/ecom_urls_for_crawling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>website</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001 Cupom de descontos</td>\n",
       "      <td>http://www.1001cupomdedescontos.com.br/</td>\n",
       "      <td>1001 Cupom de descontos is a web portal that f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101CORKS.sk</td>\n",
       "      <td>http://www.101corks.com</td>\n",
       "      <td>online wine database with shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030AM.com</td>\n",
       "      <td>http://1030am.com/</td>\n",
       "      <td>t 1030AM, we aspire to bring to you a hassle-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vision Tree Networks</td>\n",
       "      <td>http://www.10gazi.com/</td>\n",
       "      <td>Vision Tree Networks is a Korean company that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10sec</td>\n",
       "      <td>https://10s.ec/</td>\n",
       "      <td>A place for Instagramers to buy and sell.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company_name                                  website  \\\n",
       "0  1001 Cupom de descontos  http://www.1001cupomdedescontos.com.br/   \n",
       "1              101CORKS.sk                  http://www.101corks.com   \n",
       "2               1030AM.com                       http://1030am.com/   \n",
       "3     Vision Tree Networks                   http://www.10gazi.com/   \n",
       "4                    10sec                          https://10s.ec/   \n",
       "\n",
       "                                         description  \n",
       "0  1001 Cupom de descontos is a web portal that f...  \n",
       "1                 online wine database with shopping  \n",
       "2  t 1030AM, we aspire to bring to you a hassle-f...  \n",
       "3  Vision Tree Networks is a Korean company that ...  \n",
       "4          A place for Instagramers to buy and sell.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ccimports.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www3.telus.net/worldwidebotanicals/default.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>musictoyz.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beautyencounter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buyrosepetals.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          website\n",
       "0                                   ccimports.com\n",
       "1  www3.telus.net/worldwidebotanicals/default.htm\n",
       "2                                   musictoyz.com\n",
       "3                             beautyencounter.com\n",
       "4                               buyrosepetals.com"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:postgres@192.168.3.56:5432/crawler_service_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin = pd.read_sql_query('select distinct url from crawler.webpage_texts',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://123compliance.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://1for.one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://300editors.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://3plcentral.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://451degrees.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url\n",
       "0  http://123compliance.com/\n",
       "1            http://1for.one\n",
       "2     http://300editors.com/\n",
       "3     http://3plcentral.com/\n",
       "4      http://451degrees.com"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"tldextract\"\n"
     ]
    }
   ],
   "source": [
    "import tldextract\n",
    "tmp1['domain'] = tmp1['website'].fillna('').apply(lambda x:tldextract.extract(x).domain )\n",
    "tmp2['domain'] = tmp2['website'].fillna('').apply(lambda x:tldextract.extract(x).domain )\n",
    "fin['domain'] = fin['url'].fillna('').apply(lambda x:tldextract.extract(x).domain )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecom_domains_crawled = set(list(tmp1['domain'])+list(tmp2['domain'])).intersection(set(fin['domain']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17755, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_ecom = fin[fin['domain'].isin(list(ecom_domains_crawled))]\n",
    "fin_ecom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fin_ecom_unique = fin_ecom.drop_duplicates('domain')\n",
    "ecom_urls = list(set(fin_ecom_unique['url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp1,tmp2,fin,ecom_domains_crawled,fin_ecom,fin_ecom_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the above urls, we are going to do the topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_for_text_processing(cursor,urls,batch_size=2000):\n",
    "    for batch_urls in chunker(urls,batch_size):\n",
    "        if 1.0*len(batch_urls)/batch_size > 0.8: #atlease 80% of batchsize needed in a batch to process\n",
    "            query = \"select all_page_text,home_page_text from crawler.webpage_texts where url in %s\"\n",
    "            cursor.execute(query, (tuple(batch_urls),))\n",
    "            batch = cursor.fetchall()\n",
    "            if len(batch[0]) > 1:\n",
    "                yield pd.DataFrame(batch).fillna('').apply(lambda x: '. '.join(x),1)\n",
    "            else:\n",
    "                batch = [i[0] for i in batch]\n",
    "                yield pd.Series(batch).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "database='crawler_service_test'\n",
    "user='postgres'\n",
    "password='postgres'\n",
    "host='192.168.3.56'\n",
    "\n",
    "con = psycopg2.connect(database=database, user=user,password=password,host=host)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min occurance 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_yielder = load_data_for_text_processing(cursor,ecom_urls,batch_size=3500)\n",
    "\n",
    "from analytics_workbench.process_text import ProcessText\n",
    "text_processor = ProcessText()\n",
    "text_processor.generate_vectorizer_iter_list(data_yielder,vectorizer_type='Count',synonym_loc=None,\n",
    "                                stem_type=False,phrase_generation=False,\n",
    "            stop_words_loc='/home/madan/Desktop/joswin_bck/toPendrive/works/analytics_work_bench/nlp-intelligence/analytics_workbench/sample_stopwords.txt',\n",
    "                lower=True,n_gram_range=(1,2),max_df=0.9,min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3120"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_processor.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_matrix_iter(text_processor,cursor,ecom_urls,batch_size=3500):\n",
    "    for inp_series in load_data_for_text_processing(cursor,ecom_urls,batch_size):\n",
    "        yield text_processor.get_matrix_test(inp_series)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_iter = get_data_matrix_iter(text_processor,cursor,ecom_urls,3500)\n",
    "matrix_list = [i for i in matrix_iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack,vstack\n",
    "final_matrix = vstack(matrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "free, get, support, email, contact, store, online, yes, sign, pricing\n",
      "Topic #1:\n",
      "baby, gifts, gift, day, kids, new, shop, toys, love, little\n",
      "Topic #2:\n",
      "custom, print, work, made, printing, designer, photo, quality, design, look\n",
      "Topic #3:\n",
      "rs, buy, coupon, india, deals, offers, indian, get, price, mobile\n",
      "Topic #4:\n",
      "contact, solutions, services, global, commerce, gift, management, group, accessories, business\n",
      "Topic #5:\n",
      "get, one, work, make, people, time, best, like, help, need\n",
      "Topic #6:\n",
      "development, services, management, application, mobile, project, digital, business, technology, technologies\n",
      "Topic #7:\n",
      "online, commerce, ecommerce, shopping, search, shop, shoppers, stores, store, estate\n",
      "Topic #8:\n",
      "cookies, information, website, search, cookie, media, site, member, community, contact\n",
      "Topic #9:\n",
      "pinterest, map, twitter, google, map data, data, comment, content, comments, share\n",
      "Topic #10:\n",
      "travel, ver, hotel, software, booking, site, gr, pre, promo, flight\n",
      "Topic #11:\n",
      "bags, paper, bag, air, clear, tags, plastic, type, style, water\n",
      "Topic #12:\n",
      "contact, business, services, team, company, home, news, events, customer, careers\n",
      "Topic #13:\n",
      "solutions, data, software, management, product, solution, customers, business, integration, cloud\n",
      "Topic #14:\n",
      "price, shipping, order, offer, store, items, sale, free, delivery, stock\n",
      "Topic #15:\n",
      "style, src, none, height, width, display, height width, style display, width style, amp\n",
      "Topic #16:\n",
      "products, tools, parts, equipment, shop, pin, company, gear, supplies, accessories\n",
      "Topic #17:\n",
      "domain, usd, name, domain name, domains, eur, transfer, service, net, auction\n",
      "Topic #18:\n",
      "th, ca, st, series, san, city, david, american, ch, new york\n",
      "Topic #19:\n",
      "accessories, care, home, gifts, watches, sunglasses, hair, bags, covers, sports\n",
      "Topic #20:\n",
      "insurance, solutions, system, servers, systems, one, server, business, office, video\n",
      "Topic #21:\n",
      "screen, touch, samsung, iphone, cases, apple, ipad, parts, mini, covers\n",
      "Topic #22:\n",
      "information, may, use, services, service, terms, data, party, account, privacy\n",
      "Topic #23:\n",
      "ebay, marketplace, amazon, jan, dec, listing, feed, listings, sellers, channels\n",
      "Topic #24:\n",
      "women, shoes, shop, wear, new, shirts, gifts, dresses, fabric, accessories\n",
      "Topic #25:\n",
      "jewellery, black, silver, price, gold, shop, white, red, blue, color\n",
      "Topic #26:\n",
      "english, united, language, global, united states, commerce, states, science, logistics, kingdom\n",
      "Topic #27:\n",
      "view, add, cart, product, compare, quick, wishlist, details, elements, title\n",
      "Topic #28:\n",
      "books, uk, co, art, music, co uk, tv, book, dvd, games\n",
      "Topic #29:\n",
      "px, font, color, margin, width, left, padding, border, background, size\n",
      "Topic #30:\n",
      "check, make sure, sure, make, page, try, network, computer, problem, brandshortname\n",
      "Topic #31:\n",
      "open, body, cm, hair, skin, club, care, anti, oil, safety\n",
      "Topic #32:\n",
      "page, search, found, level, service, results, guide, site, visit, internet\n",
      "Topic #33:\n",
      "furniture, lighting, home, outdoor, wall, kitchen, coffee, storage, lights, table\n",
      "Topic #34:\n",
      "amp, function, amp amp, lt, document, return, gt, window, ga, length\n",
      "Topic #35:\n",
      "design, web, marketing, website, seo, services, development, web design, media, business\n",
      "Topic #36:\n",
      "img, src, width, content, jpg, height, px, img src, image, class\n",
      "Topic #37:\n",
      "mobile, android, php, windows, app, game, standard, ios, js, css\n",
      "Topic #38:\n",
      "brands, sell, retailers, retail, product, retailer, demo, request, buy, works\n",
      "Topic #39:\n",
      "islands, new, united, republic, south, australia, saint, israel, africa, china\n",
      "Topic #40:\n",
      "sales, order, style, vendors, management, service, orders, support, css, almost\n",
      "Topic #41:\n",
      "road, sector, park, ltd, group, rd, industrial, new, area, international\n",
      "Topic #42:\n",
      "payment, card, payments, credit, cash, pay, bank, checkout, credit card, data\n",
      "Topic #43:\n",
      "click, please, select, file, page, enter, name, code, close, please enter\n",
      "Topic #44:\n",
      "car, january, university, december, november, cars, year, may, september, october\n",
      "Topic #45:\n",
      "try, sound, unavailable, studio, please, advanced, temporarily, correct, back, contact\n",
      "Topic #46:\n",
      "jewelry, rings, wedding, gold, ring, diamond, glass, stone, silver, metal\n",
      "Topic #47:\n",
      "brand, video, smart, content, social, customers, product, live, marketing, user\n",
      "Topic #48:\n",
      "document, getelementbyid, url, display, style, link, style display, function, error, event\n",
      "Topic #49:\n",
      "security, secure, loading, ssl, verified, reset, fraud, safe, report, record\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from analytics_workbench.unsupervised_learning import Unsupervised\n",
    "unsup_obj = Unsupervised()\n",
    "model,mat_transform = unsup_obj.generate_topics(final_matrix,text_processor.vocabulary,'lda',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min occurance 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ProcessText' object has no attribute 'vocabulary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b827b9fbf196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mstop_words_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/madan/Desktop/joswin_bck/toPendrive/works/analytics_work_bench/nlp-intelligence/analytics_workbench/sample_stopwords.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 lower=True,n_gram_range=(1,2),max_df=0.9,min_df=0.05)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ProcessText' object has no attribute 'vocabulary'"
     ]
    }
   ],
   "source": [
    "data_yielder = load_data_for_text_processing(cursor,ecom_urls,batch_size=3500)\n",
    "\n",
    "from analytics_workbench.process_text import ProcessText\n",
    "text_processor_5pct = ProcessText()\n",
    "text_processor_5pct.generate_vectorizer_iter_list(data_yielder,vectorizer_type='Count',synonym_loc=None,\n",
    "                                stem_type=False,phrase_generation=False,\n",
    "            stop_words_loc='/home/madan/Desktop/joswin_bck/toPendrive/works/analytics_work_bench/nlp-intelligence/analytics_workbench/sample_stopwords.txt',\n",
    "                lower=True,n_gram_range=(1,2),max_df=0.9,min_df=0.05)\n",
    "len(text_processor.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_iter_5pct = get_data_matrix_iter(text_processor_5pct,cursor,ecom_urls,3500)\n",
    "matrix_list_5pct = [i for i in matrix_iter_5pct]\n",
    "final_matrix_5pct = vstack(matrix_list_5pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unsup_obj_5pct = Unsupervised()\n",
    "model_5pct,mat_transform_5pct = unsup_obj_5pct.generate_topics(final_matrix_5pct,text_processor_5pct.vocabulary,'lda',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
