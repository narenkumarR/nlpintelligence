{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# create table tmp_table_ecommerce_companies as select  * from linkedin_company_base where specialties ~* 'e(.)?commerce' ;\n",
    "engine = create_engine('postgresql://pipecandy_user:pipecandy@192.168.1.142:5432/pipecandy_db1')\n",
    "df = pd.read_sql_query(\"select distinct on (description) linkedin_url,description,specialties,website \"\\\n",
    "                       \" from (select  * from linkedin_company_base where description ~* '\\ysaas\\y')a\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9a40798692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.index = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saas_companies_data.pkl','w') as f:\n",
    "    pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'saas_companies_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94797cc72481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saas_companies_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'saas_companies_data.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('saas_companies_data.pkl','r') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk,re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from text_processing import extract_phrases\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP1: {<JJ><NN.*>+}          # Chunk sequences of JJ, NN\n",
    "  NP2: {<NN.*>+<JJ>}          # Chunk sequences of JJ, NN\n",
    "  NP3: {<NN.*>+}                  #Noun phrases\n",
    "  VP: {<VB.*><NN.*>+} # Chunk verbs and their arguments\n",
    "  \"\"\"\n",
    "phr_list = ['NP1','NP2','NP3','VP']\n",
    "tag_list = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "stop_words = stopwords.words()+['http','https','goo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar)\n",
    "pe = extract_phrases.PhraseExtractor()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "reg_exp = re.compile('[^a-zA-Z ]',re.IGNORECASE)\n",
    "def tokenizer(text):\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    phrs = pe.extract_phrase_treeinput(cp.parse(pos_tags),['NP1','NP2','VP'])\n",
    "    wrds = [snowball_stemmer.stem(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    wrds = [wrd for wrd in wrds if wrd not in stop_words]\n",
    "    phrs = ['_'.join([snowball_stemmer.stem(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    wrds = [reg_exp.sub('',i) for i in wrds]\n",
    "    return wrds+phrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11353, 4) (11353,)\n"
     ]
    }
   ],
   "source": [
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()\n",
    "print df.shape,data_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10,tokenizer=tokenizer)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_saas_companies_phrases.pkl','w') as f:\n",
    "    pickle.dump({'tfidf':tfidf,'vectorizer':tfidf_vectorizer},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_saas_companies_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)\n",
    "\n",
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NMF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-acb1456cd3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_top_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint_top_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_top_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NMF' is not defined"
     ]
    }
   ],
   "source": [
    "n_topics,n_top_words=30,20\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nmf_saas.pkl','w') as f:\n",
    "    pickle.dump(nmf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nmf_saas.pkl','r') as f:\n",
    "    nmf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mappings for topics \n",
    "topic_map_dic = {\n",
    "    0:'business process/growth strategy',1:'contact details',2:'marketing/media/branding',\n",
    "    3:'application development/web design',4:'analytics/big data',5:'project management/compliance',\n",
    "    6:'investment/venture capital',7:'branding/customer engagement platform',\n",
    "    8:'cloud computing/infrastructre/salesforce',9:'recruitment/hire talent',\n",
    "    10:'software/saas product/erp/crm',11:'sales/crm/prospecting',\n",
    "    12:'healthcare',13:'supply chain/logistics',14:'mobile/web development',15:'other language',\n",
    "    16:'saas solution provider',17:'technology/product firm',18:'consulting service/outsourcing',\n",
    "    19:'security/compliance'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "preds = nmf.transform(tfidf)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()\n",
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "0    [business process/growth strategy, marketing/m...\n",
       "1    [project management/compliance, branding/custo...\n",
       "2    [project management/compliance, branding/custo...\n",
       "3    [contact details, branding/customer engagement...\n",
       "4    [contact details, branding/customer engagement...\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_topics = preds_df.groupby('row')['col'].apply(lambda x: [topic_map_dic[i] for i in x.tolist()])\n",
    "preds_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = df.join(preds_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics.columns = ['linkedin_url','description','specialties','website','topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics.to_csv('saas_topics.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "solut provid offer saa_solut deliv industri implement base need lead support integr enterpris requir rang softwareasaservic includ year meet deploy\n",
      "Topic #1:\n",
      " saas contact email servio net info rate mobil servic mai solut audit crm recoveri backup plan java desktop financ\n",
      "Topic #2:\n",
      "market campaign autom email lead strategi generat agenc target compani optim channel digit_market search help saa roi revenu analyt bb\n",
      "Topic #3:\n",
      "develop design team expertis softwar net engin outsourc experi databas skill php mobil_applic_develop mainten qualiti work window solut applic special\n",
      "Topic #4:\n",
      "data analyt intellig insight big_data report analysi sourc decis collect visual inform integr dashboard make databas analyz machin tool use\n",
      "Topic #5:\n",
      "project construct team collabor portfolio engin ppm manag task resourc plan architect implement involv methodolog deliveri sourc execut document member\n",
      "Topic #6:\n",
      "cloud comput infrastructur paa iaa migrat base server enterpris azur deploy privat_cloud host salesforc environ amazon storag aw saa public_cloud\n",
      "Topic #7:\n",
      "servic provid host offer infrastructur support saa outsourc includ compani internet center server deliveri iaa rang deliv profession_servic centr mainten\n",
      "Topic #8:\n",
      "softwar compani saa servic licens special enterpris model use erp hardwar industri vendor distribut inc found instal base account qualiti\n",
      "Topic #9:\n",
      "consult implement strategi firm crm salesforc special train plan area servic integr expertis resourc expert specialist work erp experi execut\n",
      "Topic #10:\n",
      "custom experi relationship engag increas help deliv feedback enabl retent crm interact convers satisfact valu support acquisit success insight revenu\n",
      "Topic #11:\n",
      "manag asset report enterpris account process document properti inventori control organ track plan includ resourc mainten order facil lifecycl provid\n",
      "Topic #12:\n",
      "product build offer saa_product startup manufactur flagship base engin innov launch enterpris price bring includ idea compani rang consum lab\n",
      "Topic #13:\n",
      "platform saa_platform integr enabl allow connect use devic engag saa base offer provid creat consum marketplac built enterpris interfac communiti\n",
      "Topic #14:\n",
      "complianc risk govern grc reduc regul control ensur mitig requir autom monitor trade audit industri safeti law tax insur cost\n",
      "Topic #15:\n",
      "suppli chain logist transport visibl supplier process demand manufactur trade industri inventori food cost good distribut improv plan optim retail\n",
      "Topic #16:\n",
      "communic messag email collabor voic call unifi_communic voip sms text inform connect telecommun audienc enabl conferenc notif allow phone tool\n",
      "Topic #17:\n",
      "servicio empresa solucion sistema desarrollo tecnologa consultora desd aplicacion servio plataforma producto ao mercado modelo proyecto saa tecnolgica trav herramienta\n",
      "Topic #18:\n",
      "oper field vehicl fleet logist center compani industri cost tv effici improv provid headquart reduc offic locat facil driver sport\n",
      "Topic #19:\n",
      "sale crm lead revenu channel generat bb prospect sell account increas forc compani close call pipelin rep team growth opportun\n",
      "Topic #20:\n",
      "learn educ student train cours school machin institut teacher lms colleg univers elearn organ onlin provid learner teach campus classroom\n",
      "Topic #21:\n",
      "payment bill bank merchant process card invoic transact credit cash gateway recur pay accept subscript fraud account method collect bitcoin\n",
      "Topic #22:\n",
      "www visit inform pleas twitter facebook linkedin websit follow com check contact learn find offic headquart youtub blog call join\n",
      "Topic #23:\n",
      "client relationship firm industri success includ valu rang work support expertis help experi fortun achiev deliv deliveri meet practic need\n",
      "Topic #24:\n",
      "invest ventur capit fund entrepreneur firm compani investor startup stage focus growth seed equiti internet team saa portfolio sector financ\n",
      "Topic #25:\n",
      "gestion entrepris dvelopp mode logiciel projet mtier besoin socit informatiqu permet plateform tout produit saa spcialis solut propos donn format\n",
      "Topic #26:\n",
      "energi util build effici save consumpt water power meter asset sustain facil reduc analyt carbon grid manufactur gas cost electr\n",
      "Topic #27:\n",
      "event venu ticket organ calendar registr sport book confer meet organis fundrais particip activ club attende membership plan sponsorship exhibit\n",
      "Topic #28:\n",
      "test autom qualiti tool assur perform engin qa releas monitor framework valid analysi ab case penetr selenium laboratori convers optim\n",
      "Topic #29:\n",
      "secur protect threat access vulner ident authent cyber encrypt inform devic organ control storag detect attack firewal enterpris user cybersecur\n",
      "Topic #30:\n",
      "technolog compani industri focus innov inform expertis found year enterpris edg profession combin world deliv servic award experi cut lead\n",
      "Topic #31:\n",
      "recruit candid job hire talent search career find hr staf employ sourc execut process interview seeker resum acquisit agenc place\n",
      "Topic #32:\n",
      "health care patient healthcar hospit improv qualiti provid record physician home diseas outcom practic plan doctor engag treatment clinic well\n",
      "Topic #33:\n",
      "busi intellig process small_busi grow need help model growth focus size owner strategi understand erp plan run valu leverag core\n",
      "Topic #34:\n",
      "brand consum engag influenc retail advertis audienc agenc campaign insight promot drive world experi power build awar measur empow loyalti\n",
      "Topic #35:\n",
      "oracl sap implement fusion erp databas hcm suit e-busi_suit ibm integr java cloud peoplesoft gold special soa platinum sql middlewar\n",
      "Topic #36:\n",
      "hotel travel book reserv hospit guest properti onlin airlin tour countri revenu ota agenc trip industri destin compani resort distribut\n",
      "Topic #37:\n",
      "partner channel gold certifi resel dynam salesforc googl sap vendor integr lead microsoft includ award innov deliv isv commit migrat\n",
      "Topic #38:\n",
      "ecommerc onlin retail store order shop commerc marketplac sell inventori site websit merchant search price channel purchas convers saa integr\n",
      "Topic #39:\n",
      "applic mobil_applic enterpris build integr use perform saa_applic monitor deliv mobil host web_applic deploy desktop user crm saa run internet\n",
      "Topic #40:\n",
      "app mobil_app googl mobil build android user smartphon window store phone mobil_app_develop iphon saa devic startup ipad html tablet enterpris\n",
      "Topic #41:\n",
      "employe hr payrol employ benefit recognit workforc reward resourc hrms organ engag attend compani time hcm onboard train outsourc human_resourc\n",
      "Topic #42:\n",
      "network monitor social_network infrastructur server connect support perform internet center devic communiti design includ provid engin wireless affili world map\n",
      "Topic #43:\n",
      "help work compani team use make time peopl organ process improv tool creat need cost get user experi way perform\n",
      "Topic #44:\n",
      "content publish websit creat user curat audienc share creation engag use generat devic distribut deliv cms tv convers monet translat\n",
      "Topic #45:\n",
      "media advertis social_media publish campaign agenc facebook digit_media optim broadcast entertain analyt compani stream search target audienc includ twitter news\n",
      "Topic #46:\n",
      "system integr crm inform support implement includ erp design account process exist administr autom use cost modul track control need\n",
      "Topic #47:\n",
      "video stream tv messag webcast onlin_video conferenc share chat camera encod enterpris player live watch present audio vod mobil_devic view\n",
      "Topic #48:\n",
      "program loyalti reward card engag incent point recognit well consum drive gift retent creat promot increas execut retail purchas run\n",
      "Topic #49:\n",
      "web design site websit base mobil cms search internet seo agenc engin build sourc php use servic host work portal\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_topics,n_top_words=50,20\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# create table tmp_table_ecommerce_companies as select  * from linkedin_company_base where specialties ~* 'e(.)?commerce' ;\n",
    "engine = create_engine('postgresql://pipecandy_user:pipecandy@192.168.1.142:5432/pipecandy_db1')\n",
    "df = pd.read_sql_query(\"select distinct on (description) a.linkedin_url,description,specialties,website \"\\\n",
    "                       \" from (select a.* from linkedin_company_base a join \"\\\n",
    "                       \" linkedin_company_domains b using(linkedin_url) \"\n",
    "                       \" where description !~* '\\ysaas\\y' and specialties ~* '\\ysaas\\y' \"\\\n",
    "                       \" and b.country='UNITED STATES')a\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2888, 4) (2888,)\n"
     ]
    }
   ],
   "source": [
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()\n",
    "print df.shape,data_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_saas_companies_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf1 = tfidf_vectorizer.transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nmf_saas.pkl','r') as f:\n",
    "    nmf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = nmf.transform(tfidf1)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()\n",
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "0    [marketing/media/branding, application develop...\n",
       "1    [business process/growth strategy, contact det...\n",
       "2    [business process/growth strategy, contact det...\n",
       "3    [contact details, investment/venture capital, ...\n",
       "4    [application development/web design, project m...\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_topics = preds_df.groupby('row')['col'].apply(lambda x: [topic_map_dic[i] for i in x.tolist()])\n",
    "preds_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_topics = df.join(preds_topics)\n",
    "df_topics.columns = ['linkedin_url','description','specialties','website','topics']\n",
    "df_topics.to_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/nlp-intelligence/Concierge/ideas2it_requirement/21Sep_bay_area/us_specialties_saas_topics.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering saas companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saas_analysis/saas_companies_data.pkl','r') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>description</th>\n",
       "      <th>specialties</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/company/10dd</td>\n",
       "      <td>10DD (10 Dimension Design) is a multi-discipli...</td>\n",
       "      <td>Websites, Mobile Apps, Brand Strategy, EMarket...</td>\n",
       "      <td>http://www.10dd.co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/company/10east-corp.</td>\n",
       "      <td>10East Corp.  is a Software as a Service (SaaS...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>http://www.10east.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/company/10east-corp.</td>\n",
       "      <td>10East Corp.  is a Software as a Service (SaaS...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>http://www.10east.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/company/11giraffes</td>\n",
       "      <td>11Giraffes is a Digital Signage software compa...</td>\n",
       "      <td>Digital Signage Software as a Service</td>\n",
       "      <td>http://www.11giraffes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/company/122822</td>\n",
       "      <td>11Giraffes is a Digital Signage software compa...</td>\n",
       "      <td>Digital Signage Software as a Service</td>\n",
       "      <td>http://www.11giraffes.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    linkedin_url  \\\n",
       "0          https://www.linkedin.com/company/10dd   \n",
       "1  https://www.linkedin.com/company/10east-corp.   \n",
       "2  https://www.linkedin.com/company/10east-corp.   \n",
       "3    https://www.linkedin.com/company/11giraffes   \n",
       "4        https://www.linkedin.com/company/122822   \n",
       "\n",
       "                                         description  \\\n",
       "0  10DD (10 Dimension Design) is a multi-discipli...   \n",
       "1  10East Corp.  is a Software as a Service (SaaS...   \n",
       "2  10East Corp.  is a Software as a Service (SaaS...   \n",
       "3  11Giraffes is a Digital Signage software compa...   \n",
       "4  11Giraffes is a Digital Signage software compa...   \n",
       "\n",
       "                                         specialties  \\\n",
       "0  Websites, Mobile Apps, Brand Strategy, EMarket...   \n",
       "1                                               NULL   \n",
       "2                                               NULL   \n",
       "3              Digital Signage Software as a Service   \n",
       "4              Digital Signage Software as a Service   \n",
       "\n",
       "                     website  \n",
       "0         http://www.10dd.co  \n",
       "1      http://www.10east.com  \n",
       "2      http://www.10east.com  \n",
       "3  http://www.11giraffes.com  \n",
       "4  http://www.11giraffes.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['specialties1'] = [' '.join(set(' '.join([wrds.lower().strip()+' '+'_'.join([wrd.lower().strip() \n",
    "                                     for wrd in wrds.split(' ') if wrd])\n",
    "      for wrds in spec.split(',')]).split(' ')))\n",
    "        if spec != 'NULL' else '' for spec in df['specialties']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['description_phr'] = df['description'].apply(lambda x: ' '.join(tokenizer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('saas_analysis/saas_companies_phrases.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11353, 74)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=0.1)\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['description_phr']+df['specialties1'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11353, 74)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'allow',\n",
       " u'applic',\n",
       " u'autom',\n",
       " u'base',\n",
       " u'build',\n",
       " u'busi',\n",
       " u'business',\n",
       " u'client',\n",
       " u'cloud',\n",
       " u'compani',\n",
       " u'consult',\n",
       " u'cost',\n",
       " u'creat',\n",
       " u'crm',\n",
       " u'custom',\n",
       " u'data',\n",
       " u'deliv',\n",
       " u'design',\n",
       " u'develop',\n",
       " u'enabl',\n",
       " u'enterpris',\n",
       " u'experi',\n",
       " u'focus',\n",
       " u'help',\n",
       " u'implement',\n",
       " u'improv',\n",
       " u'includ',\n",
       " u'industri',\n",
       " u'inform',\n",
       " u'integr',\n",
       " u'internet',\n",
       " u'lead',\n",
       " u'make',\n",
       " u'manag',\n",
       " u'management',\n",
       " u'market',\n",
       " u'marketing',\n",
       " u'media',\n",
       " u'mobil',\n",
       " u'mobile',\n",
       " u'model',\n",
       " u'need',\n",
       " u'network',\n",
       " u'offer',\n",
       " u'oper',\n",
       " u'organ',\n",
       " u'partner',\n",
       " u'perform',\n",
       " u'platform',\n",
       " u'process',\n",
       " u'product',\n",
       " u'project',\n",
       " u'provid',\n",
       " u'saas',\n",
       " u'sale',\n",
       " u'secur',\n",
       " u'servic',\n",
       " u'services',\n",
       " u'softwar',\n",
       " u'software',\n",
       " u'solut',\n",
       " u'support',\n",
       " u'system',\n",
       " u'team',\n",
       " u'technolog',\n",
       " u'time',\n",
       " u'tool',\n",
       " u'use',\n",
       " u'user',\n",
       " u'web',\n",
       " u'work',\n",
       " u'world',\n",
       " u'www',\n",
       " u'year']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
