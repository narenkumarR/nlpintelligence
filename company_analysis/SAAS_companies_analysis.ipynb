{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# create table tmp_table_ecommerce_companies as select  * from linkedin_company_base where specialties ~* 'e(.)?commerce' ;\n",
    "engine = create_engine('postgresql://pipecandy_user:pipecandy@192.168.1.142:5432/pipecandy_db1')\n",
    "df = pd.read_sql_query(\"select distinct on (description) linkedin_url,description,specialties,website \"\\\n",
    "                       \" from (select  * from linkedin_company_base where description ~* '\\ysaas\\y')a\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9a40798692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.index = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saas_companies_data.pkl','w') as f:\n",
    "    pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'saas_companies_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94797cc72481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saas_companies_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'saas_companies_data.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('saas_companies_data.pkl','r') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk,re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from text_processing import extract_phrases\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP1: {<JJ><NN.*>+}          # Chunk sequences of JJ, NN\n",
    "  NP2: {<NN.*>+<JJ>}          # Chunk sequences of JJ, NN\n",
    "  NP3: {<NN.*>+}                  #Noun phrases\n",
    "  VP: {<VB.*><NN.*>+} # Chunk verbs and their arguments\n",
    "  \"\"\"\n",
    "phr_list = ['NP1','NP2','NP3','VP']\n",
    "tag_list = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "stop_words = stopwords.words()+['http','https','goo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar)\n",
    "pe = extract_phrases.PhraseExtractor()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "reg_exp = re.compile('[^a-zA-Z ]',re.IGNORECASE)\n",
    "def tokenizer(text):\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    phrs = pe.extract_phrase_treeinput(cp.parse(pos_tags),['NP1','NP2','VP'])\n",
    "    wrds = [snowball_stemmer.stem(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    wrds = [wrd for wrd in wrds if wrd not in stop_words]\n",
    "    phrs = ['_'.join([snowball_stemmer.stem(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    wrds = [reg_exp.sub('',i) for i in wrds]\n",
    "    return wrds+phrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11353, 4) (11353,)\n"
     ]
    }
   ],
   "source": [
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()\n",
    "print df.shape,data_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10,tokenizer=tokenizer)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_saas_companies_phrases.pkl','w') as f:\n",
    "    pickle.dump({'tfidf':tfidf,'vectorizer':tfidf_vectorizer},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_saas_companies_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)\n",
    "\n",
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NMF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-acb1456cd3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_top_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint_top_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_top_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NMF' is not defined"
     ]
    }
   ],
   "source": [
    "n_topics,n_top_words=30,20\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nmf_saas.pkl','w') as f:\n",
    "    pickle.dump(nmf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nmf_saas.pkl','r') as f:\n",
    "    nmf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mappings for topics \n",
    "topic_map_dic = {\n",
    "    0:'business process/growth strategy',1:'contact details',2:'marketing/media/branding',\n",
    "    3:'application development/web design',4:'analytics/big data',5:'project management/compliance',\n",
    "    6:'investment/venture capital',7:'branding/customer engagement platform',\n",
    "    8:'cloud computing/infrastructre/salesforce',9:'recruitment/hire talent',\n",
    "    10:'software/saas product/erp/crm',11:'sales/crm/prospecting',\n",
    "    12:'healthcare',13:'supply chain/logistics',14:'mobile/web development',15:'other language',\n",
    "    16:'saas solution provider',17:'technology/product firm',18:'consulting service/outsourcing',\n",
    "    19:'security/compliance'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "preds = nmf.transform(tfidf)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()\n",
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "0    [business process/growth strategy, marketing/m...\n",
       "1    [project management/compliance, branding/custo...\n",
       "2    [project management/compliance, branding/custo...\n",
       "3    [contact details, branding/customer engagement...\n",
       "4    [contact details, branding/customer engagement...\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_topics = preds_df.groupby('row')['col'].apply(lambda x: [topic_map_dic[i] for i in x.tolist()])\n",
    "preds_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = df.join(preds_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics.columns = ['linkedin_url','description','specialties','website','topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics.to_csv('saas_topics.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "solut provid offer saa_solut deliv industri implement base need lead support integr enterpris requir rang softwareasaservic includ year meet deploy\n",
      "Topic #1:\n",
      " saas contact email servio net info rate mobil servic mai solut audit crm recoveri backup plan java desktop financ\n",
      "Topic #2:\n",
      "market campaign autom email lead strategi generat agenc target compani optim channel digit_market search help saa roi revenu analyt bb\n",
      "Topic #3:\n",
      "develop design team expertis softwar net engin outsourc experi databas skill php mobil_applic_develop mainten qualiti work window solut applic special\n",
      "Topic #4:\n",
      "data analyt intellig insight big_data report analysi sourc decis collect visual inform integr dashboard make databas analyz machin tool use\n",
      "Topic #5:\n",
      "project construct team collabor portfolio engin ppm manag task resourc plan architect implement involv methodolog deliveri sourc execut document member\n",
      "Topic #6:\n",
      "cloud comput infrastructur paa iaa migrat base server enterpris azur deploy privat_cloud host salesforc environ amazon storag aw saa public_cloud\n",
      "Topic #7:\n",
      "servic provid host offer infrastructur support saa outsourc includ compani internet center server deliveri iaa rang deliv profession_servic centr mainten\n",
      "Topic #8:\n",
      "softwar compani saa servic licens special enterpris model use erp hardwar industri vendor distribut inc found instal base account qualiti\n",
      "Topic #9:\n",
      "consult implement strategi firm crm salesforc special train plan area servic integr expertis resourc expert specialist work erp experi execut\n",
      "Topic #10:\n",
      "custom experi relationship engag increas help deliv feedback enabl retent crm interact convers satisfact valu support acquisit success insight revenu\n",
      "Topic #11:\n",
      "manag asset report enterpris account process document properti inventori control organ track plan includ resourc mainten order facil lifecycl provid\n",
      "Topic #12:\n",
      "product build offer saa_product startup manufactur flagship base engin innov launch enterpris price bring includ idea compani rang consum lab\n",
      "Topic #13:\n",
      "platform saa_platform integr enabl allow connect use devic engag saa base offer provid creat consum marketplac built enterpris interfac communiti\n",
      "Topic #14:\n",
      "complianc risk govern grc reduc regul control ensur mitig requir autom monitor trade audit industri safeti law tax insur cost\n",
      "Topic #15:\n",
      "suppli chain logist transport visibl supplier process demand manufactur trade industri inventori food cost good distribut improv plan optim retail\n",
      "Topic #16:\n",
      "communic messag email collabor voic call unifi_communic voip sms text inform connect telecommun audienc enabl conferenc notif allow phone tool\n",
      "Topic #17:\n",
      "servicio empresa solucion sistema desarrollo tecnologa consultora desd aplicacion servio plataforma producto ao mercado modelo proyecto saa tecnolgica trav herramienta\n",
      "Topic #18:\n",
      "oper field vehicl fleet logist center compani industri cost tv effici improv provid headquart reduc offic locat facil driver sport\n",
      "Topic #19:\n",
      "sale crm lead revenu channel generat bb prospect sell account increas forc compani close call pipelin rep team growth opportun\n",
      "Topic #20:\n",
      "learn educ student train cours school machin institut teacher lms colleg univers elearn organ onlin provid learner teach campus classroom\n",
      "Topic #21:\n",
      "payment bill bank merchant process card invoic transact credit cash gateway recur pay accept subscript fraud account method collect bitcoin\n",
      "Topic #22:\n",
      "www visit inform pleas twitter facebook linkedin websit follow com check contact learn find offic headquart youtub blog call join\n",
      "Topic #23:\n",
      "client relationship firm industri success includ valu rang work support expertis help experi fortun achiev deliv deliveri meet practic need\n",
      "Topic #24:\n",
      "invest ventur capit fund entrepreneur firm compani investor startup stage focus growth seed equiti internet team saa portfolio sector financ\n",
      "Topic #25:\n",
      "gestion entrepris dvelopp mode logiciel projet mtier besoin socit informatiqu permet plateform tout produit saa spcialis solut propos donn format\n",
      "Topic #26:\n",
      "energi util build effici save consumpt water power meter asset sustain facil reduc analyt carbon grid manufactur gas cost electr\n",
      "Topic #27:\n",
      "event venu ticket organ calendar registr sport book confer meet organis fundrais particip activ club attende membership plan sponsorship exhibit\n",
      "Topic #28:\n",
      "test autom qualiti tool assur perform engin qa releas monitor framework valid analysi ab case penetr selenium laboratori convers optim\n",
      "Topic #29:\n",
      "secur protect threat access vulner ident authent cyber encrypt inform devic organ control storag detect attack firewal enterpris user cybersecur\n",
      "Topic #30:\n",
      "technolog compani industri focus innov inform expertis found year enterpris edg profession combin world deliv servic award experi cut lead\n",
      "Topic #31:\n",
      "recruit candid job hire talent search career find hr staf employ sourc execut process interview seeker resum acquisit agenc place\n",
      "Topic #32:\n",
      "health care patient healthcar hospit improv qualiti provid record physician home diseas outcom practic plan doctor engag treatment clinic well\n",
      "Topic #33:\n",
      "busi intellig process small_busi grow need help model growth focus size owner strategi understand erp plan run valu leverag core\n",
      "Topic #34:\n",
      "brand consum engag influenc retail advertis audienc agenc campaign insight promot drive world experi power build awar measur empow loyalti\n",
      "Topic #35:\n",
      "oracl sap implement fusion erp databas hcm suit e-busi_suit ibm integr java cloud peoplesoft gold special soa platinum sql middlewar\n",
      "Topic #36:\n",
      "hotel travel book reserv hospit guest properti onlin airlin tour countri revenu ota agenc trip industri destin compani resort distribut\n",
      "Topic #37:\n",
      "partner channel gold certifi resel dynam salesforc googl sap vendor integr lead microsoft includ award innov deliv isv commit migrat\n",
      "Topic #38:\n",
      "ecommerc onlin retail store order shop commerc marketplac sell inventori site websit merchant search price channel purchas convers saa integr\n",
      "Topic #39:\n",
      "applic mobil_applic enterpris build integr use perform saa_applic monitor deliv mobil host web_applic deploy desktop user crm saa run internet\n",
      "Topic #40:\n",
      "app mobil_app googl mobil build android user smartphon window store phone mobil_app_develop iphon saa devic startup ipad html tablet enterpris\n",
      "Topic #41:\n",
      "employe hr payrol employ benefit recognit workforc reward resourc hrms organ engag attend compani time hcm onboard train outsourc human_resourc\n",
      "Topic #42:\n",
      "network monitor social_network infrastructur server connect support perform internet center devic communiti design includ provid engin wireless affili world map\n",
      "Topic #43:\n",
      "help work compani team use make time peopl organ process improv tool creat need cost get user experi way perform\n",
      "Topic #44:\n",
      "content publish websit creat user curat audienc share creation engag use generat devic distribut deliv cms tv convers monet translat\n",
      "Topic #45:\n",
      "media advertis social_media publish campaign agenc facebook digit_media optim broadcast entertain analyt compani stream search target audienc includ twitter news\n",
      "Topic #46:\n",
      "system integr crm inform support implement includ erp design account process exist administr autom use cost modul track control need\n",
      "Topic #47:\n",
      "video stream tv messag webcast onlin_video conferenc share chat camera encod enterpris player live watch present audio vod mobil_devic view\n",
      "Topic #48:\n",
      "program loyalti reward card engag incent point recognit well consum drive gift retent creat promot increas execut retail purchas run\n",
      "Topic #49:\n",
      "web design site websit base mobil cms search internet seo agenc engin build sourc php use servic host work portal\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_topics,n_top_words=50,20\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# create table tmp_table_ecommerce_companies as select  * from linkedin_company_base where specialties ~* 'e(.)?commerce' ;\n",
    "engine = create_engine('postgresql://pipecandy_user:pipecandy@192.168.1.142:5432/pipecandy_db1')\n",
    "df = pd.read_sql_query(\"select distinct on (description) a.linkedin_url,description,specialties,website \"\\\n",
    "                       \" from (select a.* from linkedin_company_base a join \"\\\n",
    "                       \" linkedin_company_domains b using(linkedin_url) \"\n",
    "                       \" where description !~* '\\ysaas\\y' and specialties ~* '\\ysaas\\y' \"\\\n",
    "                       \" and b.country='UNITED STATES')a\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2888, 4) (2888,)\n"
     ]
    }
   ],
   "source": [
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()\n",
    "print df.shape,data_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_saas_companies_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf1 = tfidf_vectorizer.transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nmf_saas.pkl','r') as f:\n",
    "    nmf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = nmf.transform(tfidf1)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()\n",
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "0    [marketing/media/branding, application develop...\n",
       "1    [business process/growth strategy, contact det...\n",
       "2    [business process/growth strategy, contact det...\n",
       "3    [contact details, investment/venture capital, ...\n",
       "4    [application development/web design, project m...\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_topics = preds_df.groupby('row')['col'].apply(lambda x: [topic_map_dic[i] for i in x.tolist()])\n",
    "preds_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_topics = df.join(preds_topics)\n",
    "df_topics.columns = ['linkedin_url','description','specialties','website','topics']\n",
    "df_topics.to_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/nlp-intelligence/Concierge/ideas2it_requirement/21Sep_bay_area/us_specialties_saas_topics.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering saas companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saas_analysis/saas_companies_data.pkl','r') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>description</th>\n",
       "      <th>specialties</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/company/10dd</td>\n",
       "      <td>10DD (10 Dimension Design) is a multi-discipli...</td>\n",
       "      <td>Websites, Mobile Apps, Brand Strategy, EMarket...</td>\n",
       "      <td>http://www.10dd.co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/company/10east-corp.</td>\n",
       "      <td>10East Corp.  is a Software as a Service (SaaS...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>http://www.10east.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/company/10east-corp.</td>\n",
       "      <td>10East Corp.  is a Software as a Service (SaaS...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>http://www.10east.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/company/11giraffes</td>\n",
       "      <td>11Giraffes is a Digital Signage software compa...</td>\n",
       "      <td>Digital Signage Software as a Service</td>\n",
       "      <td>http://www.11giraffes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/company/122822</td>\n",
       "      <td>11Giraffes is a Digital Signage software compa...</td>\n",
       "      <td>Digital Signage Software as a Service</td>\n",
       "      <td>http://www.11giraffes.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    linkedin_url  \\\n",
       "0          https://www.linkedin.com/company/10dd   \n",
       "1  https://www.linkedin.com/company/10east-corp.   \n",
       "2  https://www.linkedin.com/company/10east-corp.   \n",
       "3    https://www.linkedin.com/company/11giraffes   \n",
       "4        https://www.linkedin.com/company/122822   \n",
       "\n",
       "                                         description  \\\n",
       "0  10DD (10 Dimension Design) is a multi-discipli...   \n",
       "1  10East Corp.  is a Software as a Service (SaaS...   \n",
       "2  10East Corp.  is a Software as a Service (SaaS...   \n",
       "3  11Giraffes is a Digital Signage software compa...   \n",
       "4  11Giraffes is a Digital Signage software compa...   \n",
       "\n",
       "                                         specialties  \\\n",
       "0  Websites, Mobile Apps, Brand Strategy, EMarket...   \n",
       "1                                               NULL   \n",
       "2                                               NULL   \n",
       "3              Digital Signage Software as a Service   \n",
       "4              Digital Signage Software as a Service   \n",
       "\n",
       "                     website  \n",
       "0         http://www.10dd.co  \n",
       "1      http://www.10east.com  \n",
       "2      http://www.10east.com  \n",
       "3  http://www.11giraffes.com  \n",
       "4  http://www.11giraffes.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['specialties1'] = [' '.join(set(' '.join([wrds.lower().strip()+' '+'_'.join([wrd.lower().strip() \n",
    "                                     for wrd in wrds.split(' ') if wrd])\n",
    "      for wrds in spec.split(',')]).split(' ')))\n",
    "        if spec != 'NULL' else '' for spec in df['specialties']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['description_phr'] = df['description'].apply(lambda x: ' '.join(tokenizer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('saas_analysis/saas_companies_phrases.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-77efb1b0935d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description_phr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'specialties1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=0.1)\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['description_phr']+df['specialties1'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 8 ms, total: 11.4 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "%time km.fit(tfidf)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11353"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "def print_top_words_in_km_cluster(km,num_clusters,vectorizer):\n",
    "    print(\"Top terms per cluster:\")\n",
    "    print()\n",
    "    #sort cluster centers by proximity to centroid\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "    vocab_frame = \n",
    "    for i in range(num_clusters):\n",
    "        print(\"Cluster %d words:\" % i, end='')\n",
    "\n",
    "        for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "            print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "        print() #add whitespace\n",
    "        print() #add whitespace\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03126529,  0.04091771,  0.02957715,  0.04496192,  0.02537285,\n",
       "         0.08138964,  0.02998261,  0.0371715 ,  0.0653549 ,  0.07545405,\n",
       "         0.01555004,  0.03449704,  0.02703104,  0.02011591,  0.07059989,\n",
       "         0.46133968,  0.04111322,  0.0242635 ,  0.03149552,  0.04181051,\n",
       "         0.03957722,  0.02706326,  0.02625611,  0.04940331,  0.01389021,\n",
       "         0.03404391,  0.03222571,  0.0422645 ,  0.05937818,  0.04704326,\n",
       "         0.01768724,  0.02314761,  0.04737619,  0.07647028,  0.03365773,\n",
       "         0.05445203,  0.01766217,  0.0222505 ,  0.0177784 ,  0.01195344,\n",
       "         0.02389594,  0.02961433,  0.02544175,  0.04596817,  0.02574508,\n",
       "         0.02577771,  0.02131932,  0.03409592,  0.09460951,  0.04335909,\n",
       "         0.05580116,  0.01301154,  0.08908443,  0.04075799,  0.01883922,\n",
       "         0.03771541,  0.07260353,  0.01524194,  0.05747771,  0.02638633,\n",
       "         0.0836581 ,  0.02974054,  0.05589831,  0.03133171,  0.06290034,\n",
       "         0.04777667,  0.05151253,  0.08114484,  0.04306426,  0.0285397 ,\n",
       "         0.031895  ,  0.03403014,  0.02997561,  0.01477147],\n",
       "       [ 0.03049473,  0.02425501,  0.02669461,  0.04475679,  0.04732678,\n",
       "         0.07877911,  0.01643322,  0.06175085,  0.02164421,  0.10041941,\n",
       "         0.02366009,  0.01907345,  0.05135214,  0.03558424,  0.08242071,\n",
       "         0.02831486,  0.02996706,  0.03138815,  0.03874337,  0.03372039,\n",
       "         0.02719039,  0.0468939 ,  0.04143745,  0.06638611,  0.01253744,\n",
       "         0.02411768,  0.03734294,  0.04062388,  0.02787442,  0.02470369,\n",
       "         0.03636764,  0.04860448,  0.03742624,  0.04988774,  0.02414728,\n",
       "         0.1583814 ,  0.05425741,  0.07913415,  0.03007872,  0.02499486,\n",
       "         0.02090168,  0.02704462,  0.03884392,  0.03853561,  0.02755408,\n",
       "         0.02607083,  0.03656058,  0.02747643,  0.11639631,  0.03071106,\n",
       "         0.07748415,  0.01738616,  0.05618872,  0.05562298,  0.07776024,\n",
       "         0.01354419,  0.06120184,  0.0125055 ,  0.04427069,  0.0303269 ,\n",
       "         0.04843565,  0.02646108,  0.02375901,  0.04593724,  0.063375  ,\n",
       "         0.04030734,  0.03936366,  0.04829056,  0.03354024,  0.03132512,\n",
       "         0.04003388,  0.02887479,  0.04894165,  0.02362279],\n",
       "       [ 0.01761135,  0.12954395,  0.01397555,  0.04935876,  0.02950229,\n",
       "         0.07547139,  0.01746689,  0.07709537,  0.04281845,  0.07353937,\n",
       "         0.04702215,  0.01757453,  0.02863709,  0.03167539,  0.05458465,\n",
       "         0.02619031,  0.02829572,  0.08612735,  0.19537857,  0.01679734,\n",
       "         0.03455439,  0.03340286,  0.03079419,  0.03249772,  0.02197847,\n",
       "         0.01542939,  0.03492315,  0.03096448,  0.02237762,  0.02536107,\n",
       "         0.05706292,  0.01667151,  0.02295429,  0.05249076,  0.02305017,\n",
       "         0.0379342 ,  0.01217955,  0.02221998,  0.0484849 ,  0.0341616 ,\n",
       "         0.02462685,  0.02626684,  0.01926821,  0.04119958,  0.01745037,\n",
       "         0.0180237 ,  0.02530382,  0.02160655,  0.03954009,  0.02554412,\n",
       "         0.08242518,  0.04562816,  0.05814564,  0.04462416,  0.01255404,\n",
       "         0.01594436,  0.12831911,  0.01765015,  0.22825133,  0.06221548,\n",
       "         0.09111056,  0.03438211,  0.05144691,  0.03956269,  0.06829531,\n",
       "         0.01838755,  0.02102442,  0.04226479,  0.02808689,  0.18733212,\n",
       "         0.03769719,  0.02002857,  0.03008932,  0.02237129],\n",
       "       [ 0.02751208,  0.04756621,  0.03143527,  0.04635707,  0.02061323,\n",
       "         0.11803012,  0.02158286,  0.06301781,  0.04789705,  0.08114709,\n",
       "         0.04765095,  0.05251023,  0.02197663,  0.02672106,  0.08456183,\n",
       "         0.03986253,  0.04950015,  0.03483353,  0.04648929,  0.03598091,\n",
       "         0.04496351,  0.03079363,  0.02928864,  0.05089583,  0.03463464,\n",
       "         0.04350791,  0.05258397,  0.05388733,  0.04683591,  0.04711747,\n",
       "         0.01681543,  0.0322983 ,  0.03004001,  0.1911152 ,  0.0561884 ,\n",
       "         0.02988018,  0.00616991,  0.00868323,  0.016771  ,  0.01289378,\n",
       "         0.03567029,  0.04810927,  0.03667318,  0.06223759,  0.05347211,\n",
       "         0.04878744,  0.04082657,  0.0314226 ,  0.04864318,  0.07389847,\n",
       "         0.06188206,  0.04909838,  0.11816302,  0.03801664,  0.02218641,\n",
       "         0.04875389,  0.15450095,  0.02418998,  0.08829217,  0.04152878,\n",
       "         0.18874032,  0.05804154,  0.0925836 ,  0.03438916,  0.07749091,\n",
       "         0.04314968,  0.03355142,  0.05060653,  0.0279902 ,  0.03011361,\n",
       "         0.03812658,  0.02887904,  0.03200369,  0.02690583],\n",
       "       [ 0.02151204,  0.08656419,  0.01878011,  0.05512234,  0.02232457,\n",
       "         0.08608087,  0.02881236,  0.05573208,  0.42799904,  0.05663001,\n",
       "         0.0401348 ,  0.0318134 ,  0.01390362,  0.04527365,  0.0543203 ,\n",
       "         0.04557985,  0.03875096,  0.02427335,  0.04833424,  0.02898149,\n",
       "         0.0532153 ,  0.02329938,  0.0286498 ,  0.03431215,  0.02237242,\n",
       "         0.01163711,  0.03276827,  0.02414879,  0.02845163,  0.03657015,\n",
       "         0.03608625,  0.02114498,  0.02455795,  0.07327039,  0.02623336,\n",
       "         0.03312643,  0.00996793,  0.01313739,  0.03206302,  0.01981013,\n",
       "         0.02493485,  0.03265484,  0.04366138,  0.04772874,  0.02524628,\n",
       "         0.02179732,  0.04968197,  0.02306863,  0.066347  ,  0.02227369,\n",
       "         0.04488432,  0.02071372,  0.08301006,  0.07188347,  0.01331054,\n",
       "         0.07119758,  0.15975457,  0.04073131,  0.07225038,  0.03940083,\n",
       "         0.10800737,  0.04173046,  0.04123945,  0.02384639,  0.06481652,\n",
       "         0.01959875,  0.01710306,  0.0350265 ,  0.02693423,  0.04411396,\n",
       "         0.02812301,  0.02345439,  0.02883311,  0.01659507]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
