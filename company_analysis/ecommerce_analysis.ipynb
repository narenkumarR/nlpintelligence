{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP1: {<JJ><NN.*>+}          # Chunk sequences of JJ, NN\n",
    "  NP2: {<NN.*>+<JJ>}          # Chunk sequences of NN and JJ\n",
    "  NP3: {<NN.*>+}                  #Noun phrases\n",
    "  VP: {<VB.*><NN.*>+} # Chunk verbs and their arguments\n",
    "  \"\"\"\n",
    "phr_list = ['NP1','NP2','NP3','VP']\n",
    "tag_list = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "import nltk,re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from text_processing import extract_phrases\n",
    "stop_words = stopwords.words()+['http','https','goo']\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "pe = extract_phrases.PhraseExtractor()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "reg_exp = re.compile('[^a-zA-Z ]',re.IGNORECASE)\n",
    "def tokenizer(text):\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    phrs = pe.extract_phrase_treeinput(cp.parse(pos_tags),['NP1','NP2','VP'])\n",
    "    wrds = [snowball_stemmer.stem(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    wrds = [wrd for wrd in wrds if wrd not in stop_words]\n",
    "    phrs = ['_'.join([snowball_stemmer.stem(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    wrds = [reg_exp.sub('',i) for i in wrds]\n",
    "    return wrds+phrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ecommerce_companies.csv',sep=';')\n",
    "df = df.dropna()\n",
    "df.index = range(df.shape[0])\n",
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10,tokenizer=tokenizer)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_ecommerce_phrases.pkl','w') as f:\n",
    "    pickle.dump({'tfidf':tfidf,'vectorizer':tfidf_vectorizer},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tfidf_ecommerce_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2645: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "solut provid custom deliv client e-commerc_solut web_solut need offer requir busi integr enterpris implement meet cost ecommerc_solut base innov_solut rang\n",
      "Topic #1:\n",
      " contact email info mai sale mobil pleas call phone partner support produto twitter rate follow servio data php expertis\n",
      "Topic #2:\n",
      "design websit_design web_design graphic_design develop print logo ident studio offer graphic base web includ brochur engin seo packag special creativ_design\n",
      "Topic #3:\n",
      "technolog compani consult inform industri enterpris innov use partner expertis focus experi firm lead data organ world leverag applic invest\n",
      "Topic #4:\n",
      "product shop custom onlin sell store retail price buy consum fashion offer marketplac platform sale make home purchas world order\n",
      "Topic #5:\n",
      "client work team project experi deliv make agenc creat year result believ peopl time understand success need take build idea\n",
      "Topic #6:\n",
      "empresa client solucion servicio diseo somo internet mai mercado desarrollo proyecto onlin resultado digit desd tecnologa marca cada producto solu\n",
      "Topic #7:\n",
      "develop applic web mobil_applic_develop php compani team project india mobil_applic web_applic_develop special product wordpress base net mainten sourc joomla outsourc\n",
      "Topic #8:\n",
      "servic provid offer compani custom qualiti support client consult rang host includ deliveri outsourc industri india oper domain wide_rang establish\n",
      "Topic #9:\n",
      "softwar compani engin develop enterpris erp outsourc custom test product hardwar system crm autom cost integr qualiti process requir comput\n",
      "Topic #10:\n",
      "payment merchant card process credit transact bank accept gateway secur account debit pay provid cash method processor acquir platform fraud\n",
      "Topic #11:\n",
      "busi help grow need custom small_busi onlin process goal improv understand get increas presenc make owner focus tool size build\n",
      "Topic #12:\n",
      "ecommerc platform magento commerc store integr retail onlin site partner sale special channel bb build focus merchant cart experi shopifi\n",
      "Topic #13:\n",
      "brand agenc fashion consum creat engag strategi media experi communic advertis build audienc ident connect luxuri content help digit_agenc campaign\n",
      "Topic #14:\n",
      "web site host internet seo agenc domain compani base cration search engin presenc optim cms registr web_solut design dvelopp rfrencement\n",
      "Topic #15:\n",
      "websit build creat search engin get seo use look wordpress host e-commerc_websit onlin page content need make presenc custom compani\n",
      "Topic #16:\n",
      "www facebook twitter visit co inform com pleas instagram follow youtub linkedin learn pinterest check uk fr compani page br\n",
      "Topic #17:\n",
      "market media search engin optim seo strategi advertis internet social_media campaign agenc social_media_market digit_market onlin email ppc googl analyt onlin_market\n",
      "Topic #18:\n",
      "manag system integr consult data content_manag_system project includ process implement order support inform applic content crm inventori sale chain enterpris\n",
      "Topic #19:\n",
      "app mobil_app mobil android iphon mobil_app_develop user platform game devic phone window ipad develop build appl android_app blackberri smartphon idea\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "n_topics,n_top_words=20,20\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "preds = nmf.transform(tfidf)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col  row\n",
       "0    1    2\n",
       "1    8    2\n",
       "2   12    2\n",
       "3   18    2\n",
       "4    1    3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mappings for topics \n",
    "topic_map_dic = {\n",
    "    0:'e-commerce solution',1:'contact info',2:'design (web,graphic)',3:'consulting',\n",
    "    4:'e-commerce store',5:'project delivery',6:'description not in english',7:'application development',\n",
    "    8:'outsourcing firm',9:'software developing',10:'payment processing',11:'help business grow',\n",
    "    12:'e-commerce platform',13:'brand strategy/marketing',14:'SEO',15:'build website/SEO',16:'social media links',\n",
    "    17:'SEO/social media marketing',18:'content management system/CRM',19:'mobile app development'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "2    [contact info, outsourcing firm, e-commerce pl...\n",
       "3    [contact info, outsourcing firm, e-commerce pl...\n",
       "4    [contact info, design (web,graphic), applicati...\n",
       "5    [e-commerce platform, SEO/social media marketing]\n",
       "6    [consulting, application development, software...\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by row to get all topics for a row\n",
    "preds_topics = preds_df.groupby('row')['col'].apply(lambda x: [topic_map_dic[i] for i in x.tolist()])\n",
    "preds_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ecommerce_companies.csv')\n",
    "df = df.dropna()\n",
    "df.index = range(df.shape[0])\n",
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   . \n",
       "1    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  ....\n",
       "2    004 Arabia is a privately owned small to mediu...\n",
       "3    004 Arabia is a privately owned small to mediu...\n",
       "4    01 Technosys is a web & mobile(iOS/Android) ap...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = df.join(preds_topics)\n",
    "df_topics.to_csv('ecommerce_topics.csv',index=False,quoting=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
