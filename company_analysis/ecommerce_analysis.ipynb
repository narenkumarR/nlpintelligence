{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP1: {<JJ><NN.*>+}          # Chunk sequences of JJ, NN\n",
    "  NP2: {<NN.*>+<JJ>}          # Chunk sequences of NN and JJ\n",
    "  NP3: {<NN.*>+}                  #Noun phrases\n",
    "  VP: {<VB.*><NN.*>+} # Chunk verbs and their arguments\n",
    "  \"\"\"\n",
    "phr_list = ['NP1','NP2','NP3','VP']\n",
    "tag_list = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "import nltk,re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from text_processing import extract_phrases\n",
    "stop_words = stopwords.words()+['http','https','goo','isnt']\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "pe = extract_phrases.PhraseExtractor()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "reg_exp = re.compile('[^a-zA-Z ]',re.IGNORECASE)\n",
    "def tokenizer(text,stem_type='lemmatize'):\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    phrs = pe.extract_phrase_treeinput(cp.parse(pos_tags),['NP1','NP2','VP'])\n",
    "    if stem_type == 'stem':\n",
    "        wrds = [snowball_stemmer.stem(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    elif stem_type == 'lemmatize':\n",
    "        wrds = [wordnet_lemmatizer.lemmatize(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    wrds = [wrd for wrd in wrds if wrd not in stop_words]\n",
    "    if stem_type == 'stem':\n",
    "        phrs = ['_'.join([snowball_stemmer.stem(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    elif stem_type == 'lemmatize':\n",
    "        phrs = ['_'.join([wordnet_lemmatizer.lemmatize(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    else:\n",
    "        phrs = ['_'.join([wrd for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    wrds = [reg_exp.sub('',i) for i in wrds]\n",
    "    return wrds+phrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ecommerce_analysis/ecommerce_companies.csv',sep=None)\n",
    "df = df.dropna()\n",
    "df.index = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    and digital_marketing_agency_specialised_in_of...\n",
       "1    e-marketing experience e-commerce user user_ex...\n",
       "2    shop and photo flexible_iterations iterations ...\n",
       "3    shop and photo flexible_iterations iterations ...\n",
       "4    e-commerce_solutions design&development experi...\n",
       "Name: specialties1, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['specialties1'] = [' '.join(set(' '.join([wrds.lower().strip()+' '+'_'.join([wrd.lower().strip() \n",
    "                                     for wrd in wrds.split(' ') if wrd])\n",
    "      for wrds in spec.split(',')]).split(' ')))\n",
    "        if spec != 'NULL' else '' for spec in df['specialties']]\n",
    "df['specialties1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['description_phr'] = df['description'].apply(lambda x: ' '.join(tokenizer(unicode(x,'ascii','ignore'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('ecommerce_analysis/ecommerce_companies_with_phrases.csv',index=False,quoting=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Matrix from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10,tokenizer=tokenizer)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_ecommerce_phrases.pkl','w') as f:\n",
    "    pickle.dump({'tfidf':tfidf,'vectorizer':tfidf_vectorizer},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tfidf_ecommerce_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2645: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "solut provid custom deliv client e-commerc_solut web_solut need offer requir busi integr enterpris implement meet cost ecommerc_solut base innov_solut rang\n",
      "Topic #1:\n",
      " contact email info mai sale mobil pleas call phone partner support produto twitter rate follow servio data php expertis\n",
      "Topic #2:\n",
      "design websit_design web_design graphic_design develop print logo ident studio offer graphic base web includ brochur engin seo packag special creativ_design\n",
      "Topic #3:\n",
      "technolog compani consult inform industri enterpris innov use partner expertis focus experi firm lead data organ world leverag applic invest\n",
      "Topic #4:\n",
      "product shop custom onlin sell store retail price buy consum fashion offer marketplac platform sale make home purchas world order\n",
      "Topic #5:\n",
      "client work team project experi deliv make agenc creat year result believ peopl time understand success need take build idea\n",
      "Topic #6:\n",
      "empresa client solucion servicio diseo somo internet mai mercado desarrollo proyecto onlin resultado digit desd tecnologa marca cada producto solu\n",
      "Topic #7:\n",
      "develop applic web mobil_applic_develop php compani team project india mobil_applic web_applic_develop special product wordpress base net mainten sourc joomla outsourc\n",
      "Topic #8:\n",
      "servic provid offer compani custom qualiti support client consult rang host includ deliveri outsourc industri india oper domain wide_rang establish\n",
      "Topic #9:\n",
      "softwar compani engin develop enterpris erp outsourc custom test product hardwar system crm autom cost integr qualiti process requir comput\n",
      "Topic #10:\n",
      "payment merchant card process credit transact bank accept gateway secur account debit pay provid cash method processor acquir platform fraud\n",
      "Topic #11:\n",
      "busi help grow need custom small_busi onlin process goal improv understand get increas presenc make owner focus tool size build\n",
      "Topic #12:\n",
      "ecommerc platform magento commerc store integr retail onlin site partner sale special channel bb build focus merchant cart experi shopifi\n",
      "Topic #13:\n",
      "brand agenc fashion consum creat engag strategi media experi communic advertis build audienc ident connect luxuri content help digit_agenc campaign\n",
      "Topic #14:\n",
      "web site host internet seo agenc domain compani base cration search engin presenc optim cms registr web_solut design dvelopp rfrencement\n",
      "Topic #15:\n",
      "websit build creat search engin get seo use look wordpress host e-commerc_websit onlin page content need make presenc custom compani\n",
      "Topic #16:\n",
      "www facebook twitter visit co inform com pleas instagram follow youtub linkedin learn pinterest check uk fr compani page br\n",
      "Topic #17:\n",
      "market media search engin optim seo strategi advertis internet social_media campaign agenc social_media_market digit_market onlin email ppc googl analyt onlin_market\n",
      "Topic #18:\n",
      "manag system integr consult data content_manag_system project includ process implement order support inform applic content crm inventori sale chain enterpris\n",
      "Topic #19:\n",
      "app mobil_app mobil android iphon mobil_app_develop user platform game devic phone window ipad develop build appl android_app blackberri smartphon idea\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "n_topics,n_top_words=20,20\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "preds = nmf.transform(tfidf)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col  row\n",
       "0    1    2\n",
       "1    8    2\n",
       "2   12    2\n",
       "3   18    2\n",
       "4    1    3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mappings for topics \n",
    "topic_map_dic = {\n",
    "    0:'e-commerce solution',1:'contact info',2:'design (web,graphic)',3:'consulting',\n",
    "    4:'e-commerce store',5:'project delivery',6:'description not in english',7:'application development',\n",
    "    8:'outsourcing firm',9:'software developing',10:'payment processing',11:'help business grow',\n",
    "    12:'e-commerce platform',13:'brand strategy/marketing',14:'SEO',15:'build website/SEO',16:'social media links',\n",
    "    17:'SEO/social media marketing',18:'content management system/CRM',19:'mobile app development'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "2    [contact info, outsourcing firm, e-commerce pl...\n",
       "3    [contact info, outsourcing firm, e-commerce pl...\n",
       "4    [contact info, design (web,graphic), applicati...\n",
       "5    [e-commerce platform, SEO/social media marketing]\n",
       "6    [consulting, application development, software...\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by row to get all topics for a row\n",
    "preds_topics = preds_df.groupby('row')['col'].apply(lambda x: [topic_map_dic[i] for i in x.tolist()])\n",
    "preds_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ecommerce_companies.csv')\n",
    "df = df.dropna()\n",
    "df.index = range(df.shape[0])\n",
    "data_samples = df['description']\n",
    "data_samples = data_samples.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   . \n",
       "1    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  ....\n",
       "2    004 Arabia is a privately owned small to mediu...\n",
       "3    004 Arabia is a privately owned small to mediu...\n",
       "4    01 Technosys is a web & mobile(iOS/Android) ap...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = df.join(preds_topics)\n",
    "df_topics.to_csv('ecommerce_topics.csv',index=False,quoting=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ecommerce_analysis/tfidf_ecommerce_with_phrases.pkl','r') as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ca55ea2b3882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36masindices\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index"
     ]
    }
   ],
   "source": [
    "tfidf,tfidf_vectorizer = tmp['tfidf'],tmp['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Company classification : Dec 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('ecommerce_analysis/ecommerce_sample_data_for_ui_with_people1.xls')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Article (formerly Bryght) delivers beautifully designed modern furniture, with outstanding attention to detail, at fair prices. Find us at our new page: https://www. linkedin. com/company/7950401Article Bryght delivers designed furniture attention detail price Find page www linkedin comcompany modern_furniture outstanding_attention fair_price new_pagearticl bryght deliv design furnitur attent detail price find page www linkedin comcompany modern_furnitur outstand_attent fair_price new_page'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['description','description_phr_lemma','description_phr']\n",
    "data_samples = df[cols[0]]\n",
    "if len(cols)>1:\n",
    "    for col in cols[1:]:\n",
    "        data_samples = data_samples + df[col]\n",
    "data_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 43)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates('company_name')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['specialties1'] = [' '.join(set(' '.join([wrds.lower().strip()+' '+'_'.join([wrd.lower().strip() \n",
    "                                     for wrd in wrds.split(' ') if wrd])\n",
    "      for wrds in spec.split(',')]).split(' ')))\n",
    "        if spec != 'NULL' else '' for spec in df['specialties']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "df['description_phr'] = df['description'].apply(lambda x: ' '.join(tokenizer(x,stem_type='stem')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "df['description_phr_lemma'] = df['description'].apply(lambda x: ' '.join(tokenizer(x,stem_type='lemmatize')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 3314)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=5)\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['description_phr_lemma']+df['specialties1'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "customer people service work business team make value world quality day offer year need employee life community experience part career\n",
      "Topic #1:\n",
      "fashion woman designer style trend look accessory shopping collection wear inspired boutique styling world clothes stylist destination size women label\n",
      "Topic #2:\n",
      "platform solution commerce ecommerce technology consumer retailer experience customer marketing sale business data content shopping mobile user software channel analytics\n",
      "Topic #3:\n",
      "www visit information commerce retail co please english read founded brands germany com internet career site website job europe learn\n",
      "Topic #4:\n",
      "group market leading leader operates portfolio distribution retail groups employee segment textile country player label good electronics dag outlet entertainment\n",
      "Topic #5:\n",
      "design quality collection style custom designer manufacturing made production create accessory world fabric new material craftsmanship york italy shirt leather\n",
      "Topic #6:\n",
      "luxury lingerie collection designer italy pre style boutique piece world experience wardrobe row swimwear editorial concierge china shopping item milan\n",
      "Topic #7:\n",
      "beauty hair skin care salon skincare cosmetic advice destination fragrance makeup cosmetics affiliate curated world panel review collection retail international_brand\n",
      "Topic #8:\n",
      "apparel footwear clothing performance gear leading industry accessories retailer manufacturing accessory young manufacturer wholesaler golf dance consulting mens lifestyle college\n",
      "Topic #9:\n",
      "pet animal supplies pet_food cat pet_supplies supply center food lover dog pets fish franchise grooming bird treat service parent st\n",
      "Topic #10:\n",
      "furniture lighting retailer office appliance bathroom bed ma kitchen room living florida patio bedroom offer dining electronics homewares accessory price\n",
      "Topic #11:\n",
      "shoe footwear shoes woman foot comfort accessory heel boot handbag designer sandal adult women style quality based show need leather\n",
      "Topic #12:\n",
      "health wellness supplement nutrition pharmacy patient vitamin supplements care natural education inc life goal agriculture products hassle carrying empower information\n",
      "Topic #13:\n",
      "flower flowers florist uk bouquet send arrangement location top make gifting wild iphone redefining reach family fr try delivers easy\n",
      "Topic #14:\n",
      "sport sports street action park league athlete licensing team polo la franchise licensed fan lifestyle culture equipment brother college headwear\n",
      "Topic #15:\n",
      "jewelry gemstone necklace fine lee television ring looking woman direct piece lifetime director accessory diamond gold take designer direct_sales diamonds\n",
      "Topic #16:\n",
      "food grocery supermarket magazine meal fresh organic foods operates market gourmet sell grocer produce giant convenience non nutrition ingredient format\n",
      "Topic #17:\n",
      "delivery ordering same grocery day restaurant city order hour moscow service beer fulfillment time startup customer option local up commerce\n",
      "Topic #18:\n",
      "brand lifestyle designed collection brands accessory woman portfolio europe menswear music leading includes consumer category sold market country marketing including\n",
      "Topic #19:\n",
      "video electronics consumer audio review interact game gaming buy tag tv beta page streaming consumer_electronics realtime matching ecommerce play conversion\n",
      "Topic #20:\n",
      "gift gifts gifting card occasion moment corporate recipient corporate_gifts personalized selection personalization wedding find chocolate joy customize candy voucher gourmet\n",
      "Topic #21:\n",
      "marketplace seller buyer online_marketplace sell commerce pre business ebay buy ecommerce selling community buying internet platform amazon technology car powering\n",
      "Topic #22:\n",
      "product offer content quality products consumer sell information range price category share provide ecommerce branded market tool create aim selling\n",
      "Topic #23:\n",
      "india times delhi tv startup lingerie snapdeal business category retail startups format gurgaon portal asia sq pan news manufacturing north\n",
      "Topic #24:\n",
      "online shopping de commerce ecommerce online_shopping para internet online_retail comercio good retail site love payments shopper clientes kid online_payments payment\n",
      "Topic #25:\n",
      "watch repair hugo watches vision pre precision time highquality manufacture aid plastic diy allow world web skill purveyor authorized country\n",
      "Topic #26:\n",
      "indonesia internet ecommerce com mean million center service youth selling provide award microsoft authorized become speak frontier seller malaysia covering\n",
      "Topic #27:\n",
      "coffee cup tea roasting cold beverage specialty machine circle starbucks box best day bar handcrafted found orlando system drink responsibility\n",
      "Topic #28:\n",
      "travel airport duty free booking traveler travel_retail operates ticket adventure hotel new industry pacific outdoors services country distribution trip seat\n",
      "Topic #29:\n",
      "wine beer wines spirits direct purchase bottle enjoy know explore qualit succeed consumer learn region taste sales un buy spirit\n",
      "Topic #30:\n",
      "store department retailer merchandise opened chain specialty operates year retail customer name country hardware state retail_store wa stores market new\n",
      "Topic #31:\n",
      "book bookseller books ebooks dvds ireland music amazon wanted year uk movie national award magazine storage retailing site healthcare everyone\n",
      "Topic #32:\n",
      "home improvement decor depot home_decor dcor furnishing garden bedroom destination electronics interior home_improvement shopping bedding style bring price offering consumer\n",
      "Topic #33:\n",
      "company inc business wa founded market operates based new russia growing manufacturing worked leading growth york worldwide leader distribution recognized\n",
      "Topic #34:\n",
      "facebook twitter instagram follow youtube pinterest google adventure blog find fr produits others uk social car page www shopping chaque\n",
      "Topic #35:\n",
      "order shipping ship multi custom amazon inventory support offer channel fulfillment shipment ebay inventory_management click save seller customer southern processing\n",
      "Topic #36:\n",
      "men clothing women clothes mens tailored s_fashion s_apparel style specializing accessories based tailoring wa casual kid pant mountain founded wear\n",
      "Topic #37:\n",
      "flooring wood south vinyl antonio selection covering floor san creating improvement one third al providing price pursuit family blog home_improvement\n",
      "Topic #38:\n",
      "united states canada kingdom franchise ascena europe operating retailer inc specialty off revenue subsidiary sears retail trading merchandise post operates\n",
      "Topic #39:\n",
      "shop way shopping street shopper london bike webshop find ecommerce city sell love experience new_way die influencers founded everyone clothes\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_topics,n_top_words=40,20\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 3314)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=5)\n",
    "tf = tf_vectorizer.fit_transform(df['description_phr_lemma']+df['specialties1'])\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "kitchen bathroom reader elevate writing publishing sustainability rewards loyalty impact content universal appliances perk allows portal resources performance engagement insight\n",
      "Topic #1:\n",
      "extra rent rental costume upload anyone rentals collaborative peer doorstep consumption appliances hotel books booking camping tools product date toys\n",
      "Topic #2:\n",
      "laboratory lab fisher science healthier innovative_technology programs patient nyse productivity solve services enable combination purchasing world customer improve research serving\n",
      "Topic #3:\n",
      "illinois king store part job www find lawn power center virginia know chemical year camping product including missouri pennsylvania feed\n",
      "Topic #4:\n",
      "king illinois chemical enjoying medication store location trip power michigan fishing missouri part including year virginia product record ohio cup\n",
      "Topic #5:\n",
      "shirts graphic age theme blend living clothes technology story option art lifestyle_brand delivery selection affordable_price platform closet connects price providing\n",
      "Topic #6:\n",
      "book photography photo camera analysis site web text ag marketing bookseller amazon ebooks dvds b2c film tag help voted garage\n",
      "Topic #7:\n",
      "bike india times business product news grocery time group get order store world delivered magazine browse brand delivery leader home\n",
      "Topic #8:\n",
      "life employee retail_location program brand gap inc banana photography republic retail plan sleepwear promote person offer coaching supporting match location\n",
      "Topic #9:\n",
      "food group retailer business customer india online sell shopping machine order times include retail manufacturing quality journey process leading learning\n",
      "Topic #10:\n",
      "couture cold celebrate distributor recommendation avenue hosting philippines catering centre convert retail_space finding returns cool dont exclusive_brand essence rating adventure\n",
      "Topic #11:\n",
      "de le france ch wij la mode service en nederland produits paris winkels met les ring magasin onze jean client\n",
      "Topic #12:\n",
      "customer wine order loyalty commerce offer instore pay in mission technology tool suite time buyer compare one treating ranging reward\n",
      "Topic #13:\n",
      "www video electronics asia singapore game united saudi kong hong gaming russia malaysia arab philippines co east consumer_electronics consumer arabia\n",
      "Topic #14:\n",
      "art artist artwork metal canvas artists creation materials tshirts is blog uk fr twitter hunting facebook america original waiting treasure\n",
      "Topic #15:\n",
      "retailer www ecommerce platform inventory powering product online technology nyc raised born saas accessories risk sell today worlds retailers added\n",
      "Topic #16:\n",
      "world beauty objective make financial_service spirit pay idea always customer supply sell passion service represents learning training detail encourage possibility\n",
      "Topic #17:\n",
      "paypal money outfitters aspect gifts class merchandise day spirit life paid clock come trendy table setting school parent way game\n",
      "Topic #18:\n",
      "brand fashion design apparel store style woman company accessory designer collection wa quality shoe clothing product world luxury www new\n",
      "Topic #19:\n",
      "brand travel consumer leading inc marketing named information opportunity deals newsletter visitor advertiser employee industry established online decision living list\n",
      "Topic #20:\n",
      "calvin klein hilfiger tommy armour van licensed caribbean heritage revenue variety associate corp brand acquired growing retail_sale heat cool going\n",
      "Topic #21:\n",
      "fashion brand retailer group shopping apparel retail product hilfiger www online growing consumer commerce tommy technology everyone conglomerate shopper home\n",
      "Topic #22:\n",
      "hall instagram beach online australia shopping order customer pinterest shop facebook lifestyle to become mens business city menswear twitter spending\n",
      "Topic #23:\n",
      "beauty train skincare panel cult retail advice online boutique guide backed filter hall online_shopping trial grooming net wash active combining\n",
      "Topic #24:\n",
      "dance banana republic supporting gap coaching isnt plan bit stretch employee love create matching interactive program www brand product were\n",
      "Topic #25:\n",
      "indonesia oliver edit award top safety consulting worker youth health sun programme heat fr household frontier asos operates beverage site\n",
      "Topic #26:\n",
      "giant diesel supermarkets denim new_product stand black currently change trail alternative flooring moving apparel_ kitchen organization living consumer_goods brand retaining\n",
      "Topic #27:\n",
      "coop vi strste danmark samt danmarks mat iso den tv dag hr butik diverse opera fr linkedin fix wholesale passion\n",
      "Topic #28:\n",
      "skin for fr garment racing performance full_line high line gas temperature oil count blend fiber clothing difference exposure utility meaning\n",
      "Topic #29:\n",
      "gift gifts occasion gifting pop wedding corporate personalization recipient corporate_gifts moment personalized awards joy winner london cooky unique_gift thank things\n",
      "Topic #30:\n",
      "product customer store company business online service brand retailer experience ecommerce commerce offer shopping www people world retail technology team\n",
      "Topic #31:\n",
      "bar un oltre qualit pizza ogni model italia grande il la wine per standard in food last za click euro\n",
      "Topic #32:\n",
      "child cancer my childhood phone children number wearing childrens donated read anyone adult theme coat conceived april dressed peace personalised\n",
      "Topic #33:\n",
      "eyeglass mother expect feminine transport image retail_partner garage specialising description located upload bridging thank middleman communication solving imagination timberland eat\n",
      "Topic #34:\n",
      "designed store travel country department retail empowering pursuit america life business ingenuity worlds maker spirit aspect creating committed paris brand\n",
      "Topic #35:\n",
      "flower flowers uk florist bouquet jewellery arrangement quality nl fr run belgium occasion lover servicing cut france box wholesaler wont\n",
      "Topic #36:\n",
      "online clientes moda de br brasil para butik el retail chile gourmet commerce empresa la grupo marcas cada en tiendas\n",
      "Topic #37:\n",
      "fraud prevention reducing detection risk faced commerce_business cloud accept score review meaning scene approval boost provides business online advanced platform\n",
      "Topic #38:\n",
      "www including point distribution player growing italy company store year fashion single sale wallet group good market situated travel leather\n",
      "Topic #39:\n",
      "estate al dubai real_estate middle la east leisure mall uae polo ray licensed entertainment partner greatness field sport holding whilst\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_topics,n_top_words=40,20\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_words_df(model, feature_names, n_top_words):\n",
    "    '''\n",
    "    :param model:\n",
    "    :param feature_names:\n",
    "    :param n_top_words:\n",
    "    :return:\n",
    "    '''\n",
    "    topic_list = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_list.append((topic_idx,\" \".join([feature_names[i]\n",
    "                                        for i in topic.argsort()[:-n_top_words - 1:-1]])))\n",
    "    return pd.DataFrame.from_records(topic_list,columns=['topic_id','top_words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'extra_rent_rental'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = get_top_words_df(lda, tf_feature_names, n_top_words)\n",
    "nmf_topics_df = get_top_words_df(nmf,tfidf_feature_names,n_top_words)\n",
    "topics_df['topic_name'] = topics_df['top_words'].apply(lambda x: '_'.join(x.split()[:3]))\n",
    "list(topics_df.ix[topics_df['topic_id']==1]['topic_name'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1941,), (1941, 3314))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np,pandas as pd\n",
    "data_samples = df['description_phr_lemma']\n",
    "data_samples.index = range(data_samples.shape[0])\n",
    "data_samples.shape,tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col  row\n",
       "0   18    0\n",
       "1   30    0\n",
       "2   30    1\n",
       "3   18    2\n",
       "4   14    3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lda.transform(tf)\n",
    "preds_probs = preds.transpose()/np.sum(preds,1)\n",
    "preds_probs = preds_probs.transpose()\n",
    "preds_ind = np.where(preds_probs>0.1)\n",
    "preds_df = pd.DataFrame({'row':preds_ind[0],'col':preds_ind[1]})\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "0          brand_fashion_design|product_customer_store\n",
       "1                               product_customer_store\n",
       "2                                 brand_fashion_design\n",
       "3    art_artist_artwork|brand_fashion_design|produc...\n",
       "4    kitchen_bathroom_reader|brand_fashion_design|p...\n",
       "Name: topic_name, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(preds_df,topics_df,how='left',left_on='col',right_on='topic_id').groupby('row')['topic_name'].\\\n",
    "                            apply(lambda x: '|'.join([i for i in x.tolist() if i !='no_topic'])).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row\n",
       "0          brand_fashion_design|product_customer_store\n",
       "1                               product_customer_store\n",
       "2                                 brand_fashion_design\n",
       "3    art_artist_artwork|brand_fashion_design|produc...\n",
       "4    kitchen_bathroom_reader|brand_fashion_design|p...\n",
       "Name: topic_name, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#below is slow implementation\n",
    "#preds_topics = preds_df.groupby('row')['col'].apply(lambda x: \n",
    "#                                    {list(topics_df.ix[(topics_df['topic_id']==i)]['topic_name'])[0] for i in x.tolist()})\n",
    "#preds_topics.head()\n",
    "pred_topics = pd.merge(preds_df,topics_df,how='left',left_on='col',right_on='topic_id').groupby('row')['topic_name'].\\\n",
    "                            apply(lambda x: '|'.join([i for i in x.tolist() if i !='no_topic'])).head()\n",
    "pred_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nmf_topics</th>\n",
       "      <th>lda_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Article Bryght delivers designed furniture att...</td>\n",
       "      <td>brand_fashion_design|product_customer_store</td>\n",
       "      <td>brand_fashion_design|product_customer_store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>something buy Want price Demand offer Flubit s...</td>\n",
       "      <td>product_customer_store</td>\n",
       "      <td>product_customer_store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend Mark Talucci Todd Elliott found inspira...</td>\n",
       "      <td>brand_fashion_design</td>\n",
       "      <td>brand_fashion_design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BucketFeet BucketFeets mission people art emer...</td>\n",
       "      <td>art_artist_artwork|brand_fashion_design|produc...</td>\n",
       "      <td>art_artist_artwork|brand_fashion_design|produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>founding Basic Resources held mission elevate ...</td>\n",
       "      <td>kitchen_bathroom_reader|brand_fashion_design|p...</td>\n",
       "      <td>kitchen_bathroom_reader|brand_fashion_design|p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Article Bryght delivers designed furniture att...   \n",
       "1  something buy Want price Demand offer Flubit s...   \n",
       "2  friend Mark Talucci Todd Elliott found inspira...   \n",
       "3  BucketFeet BucketFeets mission people art emer...   \n",
       "4  founding Basic Resources held mission elevate ...   \n",
       "\n",
       "                                          nmf_topics  \\\n",
       "0        brand_fashion_design|product_customer_store   \n",
       "1                             product_customer_store   \n",
       "2                               brand_fashion_design   \n",
       "3  art_artist_artwork|brand_fashion_design|produc...   \n",
       "4  kitchen_bathroom_reader|brand_fashion_design|p...   \n",
       "\n",
       "                                          lda_topics  \n",
       "0        brand_fashion_design|product_customer_store  \n",
       "1                             product_customer_store  \n",
       "2                               brand_fashion_design  \n",
       "3  art_artist_artwork|brand_fashion_design|produc...  \n",
       "4  kitchen_bathroom_reader|brand_fashion_design|p...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_names_df = pd.concat([data_samples,pred_topics,pred_topics],axis=1)\n",
    "topic_names_df.columns = ['text','nmf_topics','lda_topics']\n",
    "topic_names_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>top_words</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kitchen bathroom reader elevate writing publis...</td>\n",
       "      <td>kitchen_bathroom_reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>extra rent rental costume upload anyone rental...</td>\n",
       "      <td>extra_rent_rental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>laboratory lab fisher science healthier innova...</td>\n",
       "      <td>laboratory_lab_fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>illinois king store part job www find lawn pow...</td>\n",
       "      <td>illinois_king_store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>king illinois chemical enjoying medication sto...</td>\n",
       "      <td>king_illinois_chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>shirts graphic age theme blend living clothes ...</td>\n",
       "      <td>shirts_graphic_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>book photography photo camera analysis site we...</td>\n",
       "      <td>book_photography_photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>bike india times business product news grocery...</td>\n",
       "      <td>bike_india_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>life employee retail_location program brand ga...</td>\n",
       "      <td>life_employee_retail_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>food group retailer business customer india on...</td>\n",
       "      <td>food_group_retailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>couture cold celebrate distributor recommendat...</td>\n",
       "      <td>couture_cold_celebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>de le france ch wij la mode service en nederla...</td>\n",
       "      <td>de_le_france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>customer wine order loyalty commerce offer ins...</td>\n",
       "      <td>customer_wine_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>www video electronics asia singapore game unit...</td>\n",
       "      <td>www_video_electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>art artist artwork metal canvas artists creati...</td>\n",
       "      <td>art_artist_artwork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>retailer www ecommerce platform inventory powe...</td>\n",
       "      <td>retailer_www_ecommerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>world beauty objective make financial_service ...</td>\n",
       "      <td>world_beauty_objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>paypal money outfitters aspect gifts class mer...</td>\n",
       "      <td>paypal_money_outfitters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>brand fashion design apparel store style woman...</td>\n",
       "      <td>brand_fashion_design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>brand travel consumer leading inc marketing na...</td>\n",
       "      <td>brand_travel_consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>calvin klein hilfiger tommy armour van license...</td>\n",
       "      <td>calvin_klein_hilfiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>fashion brand retailer group shopping apparel ...</td>\n",
       "      <td>fashion_brand_retailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>hall instagram beach online australia shopping...</td>\n",
       "      <td>hall_instagram_beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>beauty train skincare panel cult retail advice...</td>\n",
       "      <td>beauty_train_skincare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>dance banana republic supporting gap coaching ...</td>\n",
       "      <td>dance_banana_republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>indonesia oliver edit award top safety consult...</td>\n",
       "      <td>indonesia_oliver_edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>giant diesel supermarkets denim new_product st...</td>\n",
       "      <td>giant_diesel_supermarkets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>coop vi strste danmark samt danmarks mat iso d...</td>\n",
       "      <td>coop_vi_strste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>skin for fr garment racing performance full_li...</td>\n",
       "      <td>skin_for_fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>gift gifts occasion gifting pop wedding corpor...</td>\n",
       "      <td>gift_gifts_occasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>product customer store company business online...</td>\n",
       "      <td>product_customer_store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>bar un oltre qualit pizza ogni model italia gr...</td>\n",
       "      <td>bar_un_oltre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>child cancer my childhood phone children numbe...</td>\n",
       "      <td>child_cancer_my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>eyeglass mother expect feminine transport imag...</td>\n",
       "      <td>eyeglass_mother_expect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>designed store travel country department retai...</td>\n",
       "      <td>designed_store_travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>flower flowers uk florist bouquet jewellery ar...</td>\n",
       "      <td>flower_flowers_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>online clientes moda de br brasil para butik e...</td>\n",
       "      <td>online_clientes_moda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>fraud prevention reducing detection risk faced...</td>\n",
       "      <td>fraud_prevention_reducing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>www including point distribution player growin...</td>\n",
       "      <td>www_including_point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>estate al dubai real_estate middle la east lei...</td>\n",
       "      <td>estate_al_dubai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_id                                          top_words  \\\n",
       "0          0  kitchen bathroom reader elevate writing publis...   \n",
       "1          1  extra rent rental costume upload anyone rental...   \n",
       "2          2  laboratory lab fisher science healthier innova...   \n",
       "3          3  illinois king store part job www find lawn pow...   \n",
       "4          4  king illinois chemical enjoying medication sto...   \n",
       "5          5  shirts graphic age theme blend living clothes ...   \n",
       "6          6  book photography photo camera analysis site we...   \n",
       "7          7  bike india times business product news grocery...   \n",
       "8          8  life employee retail_location program brand ga...   \n",
       "9          9  food group retailer business customer india on...   \n",
       "10        10  couture cold celebrate distributor recommendat...   \n",
       "11        11  de le france ch wij la mode service en nederla...   \n",
       "12        12  customer wine order loyalty commerce offer ins...   \n",
       "13        13  www video electronics asia singapore game unit...   \n",
       "14        14  art artist artwork metal canvas artists creati...   \n",
       "15        15  retailer www ecommerce platform inventory powe...   \n",
       "16        16  world beauty objective make financial_service ...   \n",
       "17        17  paypal money outfitters aspect gifts class mer...   \n",
       "18        18  brand fashion design apparel store style woman...   \n",
       "19        19  brand travel consumer leading inc marketing na...   \n",
       "20        20  calvin klein hilfiger tommy armour van license...   \n",
       "21        21  fashion brand retailer group shopping apparel ...   \n",
       "22        22  hall instagram beach online australia shopping...   \n",
       "23        23  beauty train skincare panel cult retail advice...   \n",
       "24        24  dance banana republic supporting gap coaching ...   \n",
       "25        25  indonesia oliver edit award top safety consult...   \n",
       "26        26  giant diesel supermarkets denim new_product st...   \n",
       "27        27  coop vi strste danmark samt danmarks mat iso d...   \n",
       "28        28  skin for fr garment racing performance full_li...   \n",
       "29        29  gift gifts occasion gifting pop wedding corpor...   \n",
       "30        30  product customer store company business online...   \n",
       "31        31  bar un oltre qualit pizza ogni model italia gr...   \n",
       "32        32  child cancer my childhood phone children numbe...   \n",
       "33        33  eyeglass mother expect feminine transport imag...   \n",
       "34        34  designed store travel country department retai...   \n",
       "35        35  flower flowers uk florist bouquet jewellery ar...   \n",
       "36        36  online clientes moda de br brasil para butik e...   \n",
       "37        37  fraud prevention reducing detection risk faced...   \n",
       "38        38  www including point distribution player growin...   \n",
       "39        39  estate al dubai real_estate middle la east lei...   \n",
       "\n",
       "                       topic_name  \n",
       "0         kitchen_bathroom_reader  \n",
       "1               extra_rent_rental  \n",
       "2           laboratory_lab_fisher  \n",
       "3             illinois_king_store  \n",
       "4          king_illinois_chemical  \n",
       "5              shirts_graphic_age  \n",
       "6          book_photography_photo  \n",
       "7                bike_india_times  \n",
       "8   life_employee_retail_location  \n",
       "9             food_group_retailer  \n",
       "10         couture_cold_celebrate  \n",
       "11                   de_le_france  \n",
       "12            customer_wine_order  \n",
       "13          www_video_electronics  \n",
       "14             art_artist_artwork  \n",
       "15         retailer_www_ecommerce  \n",
       "16         world_beauty_objective  \n",
       "17        paypal_money_outfitters  \n",
       "18           brand_fashion_design  \n",
       "19          brand_travel_consumer  \n",
       "20          calvin_klein_hilfiger  \n",
       "21         fashion_brand_retailer  \n",
       "22           hall_instagram_beach  \n",
       "23          beauty_train_skincare  \n",
       "24          dance_banana_republic  \n",
       "25          indonesia_oliver_edit  \n",
       "26      giant_diesel_supermarkets  \n",
       "27                 coop_vi_strste  \n",
       "28                    skin_for_fr  \n",
       "29            gift_gifts_occasion  \n",
       "30         product_customer_store  \n",
       "31                   bar_un_oltre  \n",
       "32                child_cancer_my  \n",
       "33         eyeglass_mother_expect  \n",
       "34          designed_store_travel  \n",
       "35              flower_flowers_uk  \n",
       "36           online_clientes_moda  \n",
       "37      fraud_prevention_reducing  \n",
       "38            www_including_point  \n",
       "39                estate_al_dubai  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
