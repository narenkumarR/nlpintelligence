{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "import tldextract,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_lkdn_cb = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/saas_classification/comps_saas_linkedin_crunchbase_jan04.csv')\n",
    "df_lkdn = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/saas_classification/comps_saas_specialty_linkedin_jan03.csv')\n",
    "df_lkdn_website_text1 = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/saas_classification/comps_saas_specialty_linkedin_jan03_1to3000_out_all_texts.csv',names=['id','website_text'])\n",
    "df_lkdn_website_text2 = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/saas_classification/comps_saas_specialty_linkedin_jan03_3001to6000_out_all_texts.csv',names=['id','website_text'])\n",
    "df_cb = pd.read_excel('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/saas_classification/USA_SAAS_CB_10Dec16.xlsx')\n",
    "df_cb_website_text = pd.read_csv('/home/madan/Desktop/joswin_bck/toPendrive/works/company_classification/nlp-intelligence/saas_classification/USA_SAAS_CB_10Dec16_website_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"tldextract\"\n"
     ]
    }
   ],
   "source": [
    "#get domains so that we can use it to join\n",
    "df_lkdn_cb['domain_cleaned'] = df_lkdn_cb['id'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df_lkdn['domain_cleaned'] = df_lkdn['id'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df_lkdn_website_text1['domain_cleaned'] = df_lkdn_website_text1['id'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df_lkdn_website_text2['domain_cleaned'] = df_lkdn_website_text2['id'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df_cb['domain_cleaned'] = df_cb['homepage_url'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df_cb_website_text['domain_cleaned'] = df_cb_website_text['website'].apply(lambda x: tldextract.extract(x.lower()).domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combining website text dfs\n",
    "df_cb_website_text.columns = ['id','website_text','domain_cleaned']\n",
    "df_website_texts = pd.concat([df_lkdn_website_text1,df_lkdn_website_text2,df_cb_website_text],ignore_index=True)\n",
    "df_website_texts['domain_cleaned'] = df_website_texts['domain_cleaned'].str.lower()\n",
    "df_lkdn['domain_cleaned'] = df_lkdn['domain_cleaned'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combining other dfs\n",
    "df_lkdn_tmp = pd.merge(df_lkdn[['domain_cleaned','description','specialties','industry']],\n",
    "               df_lkdn_cb[['domain_cleaned','description','short_description','category_list','category_group_list']],\n",
    "                       on='domain_cleaned',how='left')\n",
    "df_lkdn_tmp['descriptions'] = df_lkdn_tmp[['description_x','specialties','description_y','short_description']].fillna('').\\\n",
    "    apply(func=lambda x:' '.join([i for i in x if i]),axis=1)\n",
    "df_cb['descriptions'] = df_cb[['short_description','description']].fillna('').apply(func=lambda x:' '.join([i for i in x if i]),axis=1)\n",
    "df_lkdn_tmp['categories'] = df_lkdn_tmp[['category_list','category_group_list']].fillna('').\\\n",
    "    apply(func=lambda x:'|'.join([i for i in x if i]),axis=1)\n",
    "df_cb['categories'] = df_cb[['category_list','category_group_list']].fillna('').\\\n",
    "    apply(func=lambda x:'|'.join([i for i in x if i]),axis=1)\n",
    "df_descr_categories = pd.concat([df_lkdn_tmp[['domain_cleaned','descriptions','categories']],\n",
    "                                df_cb[['domain_cleaned','descriptions','categories']]],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/tools/merge.py:1323: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  llab = rizer.factorize(lk)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7325, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final =  pd.merge(df_descr_categories,df_website_texts[['domain_cleaned','website_text']],on='domain_cleaned')\n",
    "df_final['website_text'] = df_final['website_text'].fillna('').apply(lambda x: re.sub('\\n',' ',x))\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5322, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_final.drop_duplicates('domain_cleaned')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2679\n",
      "True     2643\n",
      "Name: categories, dtype: int64\n",
      "False    2679\n",
      "True     2643\n",
      "Name: categories, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking if any row with only space in categories\n",
    "print df_final['categories'].str.contains(r'^ *$').value_counts()\n",
    "print (df_final['categories']=='').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final_labelled = df_final[df_final['categories']!='']\n",
    "df_final_unlabelled = df_final[df_final['categories']=='']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2679, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def category_tokenizer(text):\n",
    "    ''' split by pipe (|) and return'''\n",
    "    text = text.strip()\n",
    "    text = re.sub('\\|$|^\\|','',text)\n",
    "    if text == '|':\n",
    "        return []\n",
    "    return [i.strip() for i in text.lower().split('|')]\n",
    "vectorizer = CountVectorizer(max_df=1.0, min_df=50,tokenizer=category_tokenizer,binary=True)\n",
    "dv_matrix_labelled = vectorizer.fit_transform(df_final_labelled['categories'].fillna(''))\n",
    "dv_matrix_labelled = dv_matrix_labelled.toarray()\n",
    "dv_matrix_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2643, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_matrix_unlabelled = np.zeros((df_final_unlabelled.shape[0],dv_matrix_labelled.shape[1])) - 1\n",
    "dv_matrix_unlabelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv_matrix = np.concatenate([dv_matrix_labelled,dv_matrix_unlabelled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5322, 50), (5322, 1258), (5322, 6259))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_descr = TfidfVectorizer(max_df=0.8, min_df=0.01,stop_words='english')\n",
    "X_descr_train = tfidf_vectorizer_descr.fit_transform(df_final_labelled['descriptions'].append(df_final_unlabelled['descriptions'],ignore_index=True).fillna(''))\n",
    "\n",
    "tfidf_vectorizer_website_text = TfidfVectorizer(max_df=0.8, min_df=0.01,stop_words='english')\n",
    "X_website_text_train = tfidf_vectorizer_website_text.fit_transform(df_final_labelled['website_text'].append(df_final_unlabelled['website_text'],ignore_index=True).fillna(''))\n",
    "dv_matrix.shape,X_descr_train.shape,X_website_text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c850b5572aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_cb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_cb_website_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_descr_categories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_final_labelled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_final_unlabelled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_lkdn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_lkdn_cb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_lkdn_tmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_lkdn_website_text1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_lkdn_website_text2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_website_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "del df_cb,df_cb_website_text,df_descr_categories,df_final,df_final_labelled,df_final_unlabelled,df_lkdn,df_lkdn_cb,df_lkdn_tmp,df_lkdn_website_text1,df_lkdn_website_text2,df_website_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression multi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of iterations took for fitting:75\n",
      "no of iterations took for fitting:176\n",
      "no of iterations took for fitting:79\n",
      "no of iterations took for fitting:65\n",
      "no of iterations took for fitting:106\n",
      "no of iterations took for fitting:64\n",
      "no of iterations took for fitting:182\n",
      "no of iterations took for fitting:54\n",
      "no of iterations took for fitting:176\n",
      "no of iterations took for fitting:51\n",
      "no of iterations took for fitting:65\n",
      "no of iterations took for fitting:85\n",
      "no of iterations took for fitting:56\n",
      "no of iterations took for fitting:53\n",
      "no of iterations took for fitting:282\n",
      "no of iterations took for fitting:68\n",
      "no of iterations took for fitting:49\n",
      "no of iterations took for fitting:41\n",
      "no of iterations took for fitting:132\n",
      "no of iterations took for fitting:64\n",
      "no of iterations took for fitting:367\n",
      "no of iterations took for fitting:36\n",
      "no of iterations took for fitting:136\n",
      "no of iterations took for fitting:151\n",
      "no of iterations took for fitting:87\n",
      "no of iterations took for fitting:65\n",
      "no of iterations took for fitting:347\n",
      "no of iterations took for fitting:95\n",
      "no of iterations took for fitting:528\n",
      "no of iterations took for fitting:40\n",
      "no of iterations took for fitting:197\n",
      "no of iterations took for fitting:52\n",
      "no of iterations took for fitting:248\n",
      "no of iterations took for fitting:42\n",
      "no of iterations took for fitting:52\n",
      "no of iterations took for fitting:97\n",
      "no of iterations took for fitting:107\n",
      "no of iterations took for fitting:40\n",
      "no of iterations took for fitting:47\n",
      "no of iterations took for fitting:38\n",
      "no of iterations took for fitting:510\n",
      "no of iterations took for fitting:282\n",
      "no of iterations took for fitting:38\n",
      "no of iterations took for fitting:53\n",
      "no of iterations took for fitting:38\n",
      "no of iterations took for fitting:59\n",
      "no of iterations took for fitting:502\n",
      "no of iterations took for fitting:62\n",
      "no of iterations took for fitting:44\n",
      "no of iterations took for fitting:66\n"
     ]
    }
   ],
   "source": [
    "import cotraining_multi\n",
    "print 'logistic regression multi'\n",
    "clf = cotraining_multi.CotrainMulti() #MultinomialNB(fit_prior=False)\n",
    "clf.fit(LogisticRegressionCV(class_weight='balanced',Cs=10,scoring='f1',n_jobs=1),\n",
    "        X_descr_train,X_website_text_train,dv_matrix,k=1000,u=dv_matrix_unlabelled.shape[0]//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv_labels = range(len(vectorizer.vocabulary_))\n",
    "for key in vectorizer.vocabulary_:\n",
    "    dv_labels[vectorizer.vocabulary_[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saas_multi_model_test_object.pkl','w') as f:\n",
    "    pickle.dump({'model':clf,'website_text_vectorizer':tfidf_vectorizer_website_text,\n",
    "                'description_vectorizer':tfidf_vectorizer_descr,'dv_labels':dv_labels},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'advertising',\n",
       " u'analytics',\n",
       " u'apps',\n",
       " u'b2b',\n",
       " u'big data',\n",
       " u'business intelligence',\n",
       " u'cloud computing',\n",
       " u'collaboration',\n",
       " u'commerce and shopping',\n",
       " u'consulting',\n",
       " u'content and publishing',\n",
       " u'crm',\n",
       " u'curated web',\n",
       " u'customer service',\n",
       " u'data and analytics',\n",
       " u'design',\n",
       " u'developer tools',\n",
       " u'digital media',\n",
       " u'e-commerce',\n",
       " u'education',\n",
       " u'enterprise software',\n",
       " u'finance',\n",
       " u'financial services',\n",
       " u'hardware',\n",
       " u'health care',\n",
       " u'human resources',\n",
       " u'information technology',\n",
       " u'internet',\n",
       " u'internet services',\n",
       " u'marketing automation',\n",
       " u'media and entertainment',\n",
       " u'messaging and telecommunications',\n",
       " u'mobile',\n",
       " u'paas',\n",
       " u'payments',\n",
       " u'privacy and security',\n",
       " u'professional services',\n",
       " u'project management',\n",
       " u'real estate',\n",
       " u'recruiting',\n",
       " u'saas',\n",
       " u'sales and marketing',\n",
       " u'science and engineering',\n",
       " u'security',\n",
       " u'small and medium businesses',\n",
       " u'social media',\n",
       " u'software',\n",
       " u'transportation',\n",
       " u'video',\n",
       " u'web development']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting predictions for unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saas_multi_model_test_object.pkl','r') as f:\n",
    "    tmp = pickle.load(f)\n",
    "\n",
    "model,website_text_vectorizer,description_vectorizer,dv_labels = tmp['model'],tmp['website_text_vectorizer'],tmp['description_vectorizer'],tmp['dv_labels']\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2643, 1258), (2643, 6259))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_descr = description_vectorizer.transform(df_final_unlabelled['descriptions'])\n",
    "X_website_text = website_text_vectorizer.transform(df_final_unlabelled['website_text'])\n",
    "X_descr.shape,X_website_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advertising</th>\n",
       "      <th>analytics</th>\n",
       "      <th>apps</th>\n",
       "      <th>b2b</th>\n",
       "      <th>big data</th>\n",
       "      <th>business intelligence</th>\n",
       "      <th>cloud computing</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>commerce and shopping</th>\n",
       "      <th>consulting</th>\n",
       "      <th>...</th>\n",
       "      <th>saas</th>\n",
       "      <th>sales and marketing</th>\n",
       "      <th>science and engineering</th>\n",
       "      <th>security</th>\n",
       "      <th>small and medium businesses</th>\n",
       "      <th>social media</th>\n",
       "      <th>software</th>\n",
       "      <th>transportation</th>\n",
       "      <th>video</th>\n",
       "      <th>web development</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   advertising  analytics  apps  b2b  big data  business intelligence  \\\n",
       "0          0.0        0.0   0.0  0.0       0.0                    0.0   \n",
       "1          1.0        1.0   0.0  0.0       0.0                    0.0   \n",
       "2          0.0        0.0   1.0  0.0       0.0                    0.0   \n",
       "3          0.0        0.0   1.0  0.0       0.0                    0.0   \n",
       "4          0.0        0.0   0.0  0.0       1.0                    0.0   \n",
       "\n",
       "   cloud computing  collaboration  commerce and shopping  consulting  \\\n",
       "0              0.0            0.0                    1.0         0.0   \n",
       "1              0.0            0.0                    0.0         0.0   \n",
       "2              0.0            0.0                    0.0         0.0   \n",
       "3              0.0            0.0                    0.0         0.0   \n",
       "4              1.0            0.0                    0.0         0.0   \n",
       "\n",
       "        ...         saas  sales and marketing  science and engineering  \\\n",
       "0       ...          1.0                  0.0                      0.0   \n",
       "1       ...          1.0                  1.0                      0.0   \n",
       "2       ...          0.0                  0.0                      0.0   \n",
       "3       ...          0.0                  0.0                      0.0   \n",
       "4       ...          0.0                  0.0                      0.0   \n",
       "\n",
       "   security  small and medium businesses  social media  software  \\\n",
       "0       0.0                          0.0           0.0       0.0   \n",
       "1       0.0                          0.0           0.0       1.0   \n",
       "2       0.0                          0.0           0.0       1.0   \n",
       "3       0.0                          0.0           0.0       1.0   \n",
       "4       0.0                          0.0           0.0       1.0   \n",
       "\n",
       "   transportation  video  web development  \n",
       "0             0.0    0.0              0.0  \n",
       "1             0.0    0.0              0.0  \n",
       "2             0.0    0.0              0.0  \n",
       "3             0.0    0.0              0.0  \n",
       "4             0.0    0.0              0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_descr,X_website_text)\n",
    "preds_df = pd.DataFrame(preds,columns=dv_labels)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final_unlabelled.index = range(df_final_unlabelled.shape[0])\n",
    "df_unlab_preds = pd.concat([df_final_unlabelled[['domain_cleaned','descriptions']],preds_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_cleaned</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>advertising</th>\n",
       "      <th>analytics</th>\n",
       "      <th>apps</th>\n",
       "      <th>b2b</th>\n",
       "      <th>big data</th>\n",
       "      <th>business intelligence</th>\n",
       "      <th>cloud computing</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>...</th>\n",
       "      <th>saas</th>\n",
       "      <th>sales and marketing</th>\n",
       "      <th>science and engineering</th>\n",
       "      <th>security</th>\n",
       "      <th>small and medium businesses</th>\n",
       "      <th>social media</th>\n",
       "      <th>software</th>\n",
       "      <th>transportation</th>\n",
       "      <th>video</th>\n",
       "      <th>web development</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1С-edi</td>\n",
       "      <td>1C Net (\"1C-Сеть\" in Russian) was founded by R...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020thinkology</td>\n",
       "      <td>We find future success for our clients. Four k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2boandco</td>\n",
       "      <td>Société de conseil en solutions SAAS (Software...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360medical</td>\n",
       "      <td>&gt; 360 medics, la 1ère application sur le bon u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4clouds</td>\n",
       "      <td>We design, configure, deploy and maintain netw...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain_cleaned                                       descriptions  \\\n",
       "0          1С-edi  1C Net (\"1C-Сеть\" in Russian) was founded by R...   \n",
       "1  2020thinkology  We find future success for our clients. Four k...   \n",
       "2        2boandco  Société de conseil en solutions SAAS (Software...   \n",
       "3      360medical  > 360 medics, la 1ère application sur le bon u...   \n",
       "4         4clouds  We design, configure, deploy and maintain netw...   \n",
       "\n",
       "   advertising  analytics  apps  b2b  big data  business intelligence  \\\n",
       "0          0.0        0.0   0.0  0.0       0.0                    0.0   \n",
       "1          1.0        1.0   0.0  0.0       0.0                    0.0   \n",
       "2          0.0        0.0   1.0  0.0       0.0                    0.0   \n",
       "3          0.0        0.0   1.0  0.0       0.0                    0.0   \n",
       "4          0.0        0.0   0.0  0.0       1.0                    0.0   \n",
       "\n",
       "   cloud computing  collaboration       ...         saas  sales and marketing  \\\n",
       "0              0.0            0.0       ...          1.0                  0.0   \n",
       "1              0.0            0.0       ...          1.0                  1.0   \n",
       "2              0.0            0.0       ...          0.0                  0.0   \n",
       "3              0.0            0.0       ...          0.0                  0.0   \n",
       "4              1.0            0.0       ...          0.0                  0.0   \n",
       "\n",
       "   science and engineering  security  small and medium businesses  \\\n",
       "0                      0.0       0.0                          0.0   \n",
       "1                      0.0       0.0                          0.0   \n",
       "2                      0.0       0.0                          0.0   \n",
       "3                      0.0       0.0                          0.0   \n",
       "4                      0.0       0.0                          0.0   \n",
       "\n",
       "   social media  software  transportation  video  web development  \n",
       "0           0.0       0.0             0.0    0.0              0.0  \n",
       "1           0.0       1.0             0.0    0.0              0.0  \n",
       "2           0.0       1.0             0.0    0.0              0.0  \n",
       "3           0.0       1.0             0.0    0.0              0.0  \n",
       "4           0.0       1.0             0.0    0.0              0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlab_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_unlab_preds.to_csv('saas_model_predictions.csv',index=False,quoting=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2643, 52)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlab_preds.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
