{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('USA_SAAS_CB_10Dec16.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2572, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['category_list'])\n",
    "df.index = range(len(df))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1933\n",
      "1     639\n",
      "Name: enterprise_software_present, dtype: int64\n",
      "0    2218\n",
      "1     354\n",
      "Name: cloud, dtype: int64\n",
      "0    2423\n",
      "1     149\n",
      "Name: crm, dtype: int64\n",
      "0    2206\n",
      "1     366\n",
      "Name: mobile, dtype: int64\n",
      "0    2248\n",
      "1     324\n",
      "Name: analytics, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['enterprise_software_present'] = df['category_list'].apply(lambda x:1 if x and 'enterprise software' in x else 0)\n",
    "df['cloud'] = df['category_list'].apply(lambda x:1 if x and 'cloud' in x else 0)\n",
    "df['crm'] = df['category_list'].apply(lambda x:1 if x and 'crm' in x else 0)\n",
    "df['mobile'] = df['category_list'].apply(lambda x:1 if x and 'mobile' in x else 0)\n",
    "df['analytics'] = df['category_list'].apply(lambda x:1 if x and 'analytics' in x else 0)\n",
    "print df['enterprise_software_present'].value_counts()\n",
    "print df['cloud'].value_counts()\n",
    "print df['crm'].value_counts()\n",
    "print df['mobile'].value_counts()\n",
    "print df['analytics'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoho offers a suite of business, collaboration...</td>\n",
       "      <td>Founded in 1996, Zoho Corporation is the softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GoFormz is helping customers to transform into...</td>\n",
       "      <td>GoFormz lets businesses capture data electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acumatica is a provider of cloud business mana...</td>\n",
       "      <td>Acumatica is a leading provider of cloud busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marketing automation for tax and accounting pr...</td>\n",
       "      <td>ClientWhys is a Software as a Service (SaaS) c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everbill enables startups and SMEs to create i...</td>\n",
       "      <td>With everbill startups and SMEs can easily cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description  \\\n",
       "0  Zoho offers a suite of business, collaboration...   \n",
       "1  GoFormz is helping customers to transform into...   \n",
       "2  Acumatica is a provider of cloud business mana...   \n",
       "3  Marketing automation for tax and accounting pr...   \n",
       "4  everbill enables startups and SMEs to create i...   \n",
       "\n",
       "                                         description  \n",
       "0  Founded in 1996, Zoho Corporation is the softw...  \n",
       "1  GoFormz lets businesses capture data electroni...  \n",
       "2  Acumatica is a leading provider of cloud busin...  \n",
       "3  ClientWhys is a Software as a Service (SaaS) c...  \n",
       "4  With everbill startups and SMEs can easily cre...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['short_description','description']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# phrase generation\n",
    "# not used because taking too much time to run\n",
    "import nltk,re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import extract_phrases\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NP1: {<JJ><NN.*>+}          # Chunk sequences of JJ, NN\n",
    "  NP2: {<NN.*>+<JJ>}          # Chunk sequences of NN and JJ\n",
    "  NP3: {<NN.*>+}                  #Noun phrases\n",
    "  VP: {<VB.*><NN.*>+} # Chunk verbs and their arguments\n",
    "  \"\"\"\n",
    "# phr_list = ['NP1','NP2','NP3','VP']\n",
    "phr_list = ['NP1','NP2','VP']\n",
    "tag_list = ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "stop_words = stopwords.words()+['http','https','goo','isnt']\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "pe = extract_phrases.PhraseExtractor()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "reg_exp = re.compile('[^a-zA-Z ]',re.IGNORECASE)\n",
    "def tokenizer(text,stem_type='lemmatize'):\n",
    "    '''\n",
    "    :param text:\n",
    "    :param stem_type: type of stemming to be done\n",
    "    :return:\n",
    "    '''\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    phrs = pe.extract_phrase_treeinput(cp.parse(pos_tags),phr_list)\n",
    "    if stem_type == 'stem':\n",
    "        wrds = [snowball_stemmer.stem(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    elif stem_type == 'lemmatize':\n",
    "        wrds = [wordnet_lemmatizer.lemmatize(i[0]) for i in pos_tags if i[1] in tag_list]\n",
    "    else:\n",
    "        wrds = [i[0] for i in pos_tags if i[1]in tag_list]\n",
    "    wrds = [wrd for wrd in wrds if wrd not in stop_words]\n",
    "    if stem_type == 'stem':\n",
    "        phrs = ['_'.join([snowball_stemmer.stem(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    elif stem_type == 'lemmatize':\n",
    "        phrs = ['_'.join([wordnet_lemmatizer.lemmatize(wrd) for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    else:\n",
    "        phrs = ['_'.join([wrd for wrd in nltk.word_tokenize(phr)]) for phr in phrs]\n",
    "    wrds = [reg_exp.sub('',i) for i in wrds]\n",
    "    return wrds+phrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['short_description_clean'] = df['short_description'].fillna('').apply(lambda x: ' '.join(tokenizer(x,stem_type='lemmatize')))\n",
    "#df['description_clean'] = df['description'].fillna('').apply(lambda x: ' '.join(tokenizer(x,stem_type='lemmatize')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2064, 126), (2064, 1083))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "train.index = range(len(train))\n",
    "test.index = range(len(test))\n",
    "\n",
    "tfidf_vectorizer_short_descr = TfidfVectorizer(max_df=0.8, min_df=0.01,stop_words='english')\n",
    "X_short_descr_train = tfidf_vectorizer_short_descr.fit_transform(train['short_description'].fillna(''))\n",
    "X_short_descr_test = tfidf_vectorizer_short_descr.transform(test['short_description'].fillna(''))\n",
    "tfidf_vectorizer_descr = TfidfVectorizer(max_df=0.8, min_df=0.01,stop_words='english')\n",
    "X_descr_train = tfidf_vectorizer_descr.fit_transform(train['description'].fillna(''))\n",
    "X_descr_test = tfidf_vectorizer_descr.transform(test['description'].fillna(''))\n",
    "X_short_descr_train.shape,X_descr_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1550\n",
       "1     514\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train,y_test = train['enterprise_software_present'],test['enterprise_software_present']\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    1059\n",
       " 0     768\n",
       " 1     237\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting random 50% y_train as -1 (unlabelled)\n",
    "msk1 = np.random.rand(len(y_train)) < 0.5\n",
    "y_train[msk1] = -1\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train_labelled = hstack([X_short_descr_train[~msk1,:],X_descr_train[~msk1,:]])\n",
    "y_train_labelled = y_train[~msk1]\n",
    "X_test = hstack([X_short_descr_test,X_descr_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sklearn_cotraining.classifiers' from 'sklearn_cotraining/classifiers.pyc'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn_cotraining.classifiers import CoTrainingClassifier\n",
    "import sklearn_cotraining.classifiers\n",
    "reload(sklearn_cotraining.classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.85       383\n",
      "          1       0.48      0.10      0.16       125\n",
      "\n",
      "avg / total       0.70      0.75      0.68       508\n",
      "\n",
      "Logistic CoTraining\n",
      "no of iterations took for fitting:194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.99      0.86       383\n",
      "          1       0.60      0.05      0.09       125\n",
      "\n",
      "avg / total       0.72      0.76      0.67       508\n",
      "\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.85       383\n",
      "          1       0.48      0.10      0.16       125\n",
      "\n",
      "avg / total       0.70      0.75      0.68       508\n",
      "\n",
      "SVM CoTraining\n",
      "no of iterations took for fitting:164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.95      0.85       383\n",
      "          1       0.51      0.15      0.23       125\n",
      "\n",
      "avg / total       0.71      0.76      0.70       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic'\n",
    "base_lr = LogisticRegression()\n",
    "base_lr.fit(X_train_labelled, y_train_labelled)\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'Logistic CoTraining'\n",
    "lg_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(LogisticRegression(),u=len(y_train)//10,k=1000)\n",
    "lg_co_clf.fit(X_short_descr_train, X_descr_train, y_train)\n",
    "y_pred = lg_co_clf.predict(X_short_descr_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'SVM'\n",
    "base_svm = SVC(kernel='linear')\n",
    "base_svm.fit(X_train_labelled, y_train_labelled)\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'SVM CoTraining'\n",
    "svm_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(SVC(kernel='linear',probability=True), \n",
    "                                                                 u=len(y_train)//10,k=1000)\n",
    "svm_co_clf.fit(X_short_descr_train, X_descr_train, y_train)\n",
    "y_pred = svm_co_clf.predict(X_short_descr_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 80% unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1563\n",
       "1     507\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "train.index = range(len(train))\n",
    "test.index = range(len(test))\n",
    "y_train,y_test = train['enterprise_software_present'],test['enterprise_software_present']\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    1650\n",
       " 0     310\n",
       " 1     110\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting random 80% y_train as -1 (unlabelled)\n",
    "msk1 = np.random.rand(len(y_train)) < 0.8\n",
    "y_train[msk1] = -1\n",
    "X_train_labelled = hstack([X_short_descr_train[~msk1,:],X_descr_train[~msk1,:]])\n",
    "y_train_labelled = y_train[~msk1]\n",
    "X_test = hstack([X_short_descr_test,X_descr_test])\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.99      0.85       370\n",
      "          1       0.70      0.05      0.10       132\n",
      "\n",
      "avg / total       0.73      0.75      0.65       502\n",
      "\n",
      "Logistic CoTraining\n",
      "no of iterations took for fitting:331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       370\n",
      "          1       0.00      0.00      0.00       132\n",
      "\n",
      "avg / total       0.54      0.74      0.63       502\n",
      "\n",
      "SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.99      0.85       370\n",
      "          1       0.70      0.05      0.10       132\n",
      "\n",
      "avg / total       0.73      0.75      0.65       502\n",
      "\n",
      "SVM CoTraining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of iterations took for fitting:66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       370\n",
      "          1       1.00      0.01      0.02       132\n",
      "\n",
      "avg / total       0.81      0.74      0.63       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic'\n",
    "base_lr = LogisticRegression()\n",
    "base_lr.fit(X_train_labelled, y_train_labelled)\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'Logistic CoTraining'\n",
    "lg_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(LogisticRegression(),u=len(y_train)//10,k=1000)\n",
    "lg_co_clf.fit(X_short_descr_train, X_descr_train, y_train)\n",
    "y_pred = lg_co_clf.predict(X_short_descr_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'SVM'\n",
    "base_svm = LinearSVC()\n",
    "base_svm.fit(X_train_labelled, y_train_labelled)\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'SVM CoTraining'\n",
    "svm_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(LinearSVC(), u=len(y_train)//10,k=1000)\n",
    "svm_co_clf.fit(X_short_descr_train, X_descr_train, y_train)\n",
    "y_pred = svm_co_clf.predict(X_short_descr_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90% unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1550\n",
       "1     514\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "train.index = range(len(train))\n",
    "test.index = range(len(test))\n",
    "y_train,y_test = train['enterprise_software_present'],test['enterprise_software_present']\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    1864\n",
       " 0     143\n",
       " 1      57\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting random 90% y_train as -1 (unlabelled)\n",
    "msk1 = np.random.rand(len(y_train)) < 0.9\n",
    "y_train[msk1] = -1\n",
    "X_train_labelled = hstack([X_short_descr_train[~msk1,:],X_descr_train[~msk1,:]])\n",
    "y_train_labelled = y_train[~msk1]\n",
    "X_test = hstack([X_short_descr_test,X_descr_test])\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.99      0.87       383\n",
      "          1       0.82      0.07      0.13       125\n",
      "\n",
      "avg / total       0.78      0.77      0.69       508\n",
      "\n",
      "Logistic CoTraining\n",
      "no of iterations took for fitting:374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86       383\n",
      "          1       0.00      0.00      0.00       125\n",
      "\n",
      "avg / total       0.57      0.75      0.65       508\n",
      "\n",
      "SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.99      0.87       383\n",
      "          1       0.82      0.07      0.13       125\n",
      "\n",
      "avg / total       0.78      0.77      0.69       508\n",
      "\n",
      "SVM CoTraining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of iterations took for fitting:267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80       383\n",
      "          1       0.33      0.24      0.28       125\n",
      "\n",
      "avg / total       0.66      0.69      0.67       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic'\n",
    "base_lr = LogisticRegression()\n",
    "base_lr.fit(X_train_labelled, y_train_labelled)\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'Logistic CoTraining'\n",
    "lg_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(LogisticRegression(), u=len(y_train)//10,k=1000)\n",
    "lg_co_clf.fit(X_short_descr_train, X_descr_train, y_train)\n",
    "y_pred = lg_co_clf.predict(X_short_descr_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'SVM'\n",
    "base_svm = SVC(kernel='linear')\n",
    "base_svm.fit(X_train_labelled, y_train_labelled)\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print 'SVM CoTraining'\n",
    "svm_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(SVC(kernel='linear',probability=True),\n",
    "                                                                 u=len(y_train)//10, k=1000)\n",
    "svm_co_clf.fit(X_short_descr_train, X_descr_train, y_train)\n",
    "y_pred = svm_co_clf.predict(X_short_descr_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## add website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('USA_SAAS_CB_10Dec16.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2572, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['category_list'])\n",
    "df.index = range(len(df))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1933\n",
       "1     639\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['enterprise_software_present'] = df['category_list'].apply(lambda x:1 if x and 'enterprise software' in x else 0)\n",
    "df['enterprise_software_present'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import nltk,re\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2056, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('USA_SAAS_CB_10Dec16_website_text.csv')\n",
    "df1['website_text'] = df1['website_text'].apply(lambda x: re.sub('\\n',' ',x))\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"tldextract\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>website_text</th>\n",
       "      <th>domain_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>http://www.cisco.com/web/about/ac49/ac0/ac1/ac...</td>\n",
       "      <td>Cisco Announces Acquisition of ThinkSmart Tech...</td>\n",
       "      <td>cisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>http://macheen.com</td>\n",
       "      <td>www.macheen.com</td>\n",
       "      <td>macheen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>http://www.rtpholdings.com</td>\n",
       "      <td>RTP Holdings - RTP Holdings Home Solution Bene...</td>\n",
       "      <td>rtpholdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>http://seatserve.com</td>\n",
       "      <td>SeatServe - Stay Seated. In-Seat Delivery at Y...</td>\n",
       "      <td>seatserve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>http://www.contentlaunch.com/</td>\n",
       "      <td>Content Marketing Software | Content Writing S...</td>\n",
       "      <td>contentlaunch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                website  \\\n",
       "2051  http://www.cisco.com/web/about/ac49/ac0/ac1/ac...   \n",
       "2052                                 http://macheen.com   \n",
       "2053                         http://www.rtpholdings.com   \n",
       "2054                               http://seatserve.com   \n",
       "2055                      http://www.contentlaunch.com/   \n",
       "\n",
       "                                           website_text domain_cleaned  \n",
       "2051  Cisco Announces Acquisition of ThinkSmart Tech...          cisco  \n",
       "2052                                    www.macheen.com        macheen  \n",
       "2053  RTP Holdings - RTP Holdings Home Solution Bene...    rtpholdings  \n",
       "2054  SeatServe - Stay Seated. In-Seat Delivery at Y...      seatserve  \n",
       "2055  Content Marketing Software | Content Writing S...  contentlaunch  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tldextract\n",
    "df1['domain_cleaned'] = df1['website'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1906, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.drop_duplicates('domain_cleaned')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2391, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain_cleaned'] = df['homepage_url'].apply(lambda x: tldextract.extract(x.lower()).domain)\n",
    "df = df.drop_duplicates('domain_cleaned')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2391, 22), (1906, 3), (1893, 24))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(df,df1,on='domain_cleaned')\n",
    "df.shape,df1.shape,df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>li_cpy_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>category_list</th>\n",
       "      <th>category_group_list</th>\n",
       "      <th>industry</th>\n",
       "      <th>short_description</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>last_funding_on</th>\n",
       "      <th>homepage_url</th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>enterprise_software_present</th>\n",
       "      <th>domain_cleaned</th>\n",
       "      <th>website</th>\n",
       "      <th>website_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>NuORDER</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>b2b|e-commerce|fashion|internet|saas|wholesale</td>\n",
       "      <td>commerce and shopping|design|internet services</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>NuORDER is a cloud &amp; mobile B2B eCommerce plat...</td>\n",
       "      <td>NuORDER empowers B2B eCommerce sites for over ...</td>\n",
       "      <td>...</td>\n",
       "      <td>13900000.0</td>\n",
       "      <td>2015-02-01 00:00:00</td>\n",
       "      <td>http://www.nuorder.com</td>\n",
       "      <td>http://www.linkedin.com/company/2779405</td>\n",
       "      <td>nuorder.com</td>\n",
       "      <td>info@nuorder.com</td>\n",
       "      <td>0</td>\n",
       "      <td>nuorder</td>\n",
       "      <td>http://www.nuorder.com</td>\n",
       "      <td>NuORDER #1 B2B eCommerce Solution BRANDS RETAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>EvoNexus (CommNexus)</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>La Jolla</td>\n",
       "      <td>big data|cyber security|hardware|life science|...</td>\n",
       "      <td>biotechnology|data and analytics|hardware|info...</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>EvoNexus is a non-profit technology incubator ...</td>\n",
       "      <td>EvoNexus (formerly CommNexus, formerly the Tel...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.evonexus.org</td>\n",
       "      <td>http://www.linkedin.com/company/commnexus</td>\n",
       "      <td>evonexus.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>evonexus</td>\n",
       "      <td>http://www.evonexus.org</td>\n",
       "      <td>EvoNexus Jobs Contact Us Resources About About...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>Macheen Inc</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>enterprise software|internet|saas</td>\n",
       "      <td>internet services|software</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>Macheen is a SaaS-based platform that brings m...</td>\n",
       "      <td>Macheen, Inc is a SaaS company that brings mob...</td>\n",
       "      <td>...</td>\n",
       "      <td>34394995.0</td>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>http://macheen.com</td>\n",
       "      <td>https://www.linkedin.com/company/macheen-inc</td>\n",
       "      <td>macheen.com</td>\n",
       "      <td>info@macheen.com</td>\n",
       "      <td>1</td>\n",
       "      <td>macheen</td>\n",
       "      <td>http://macheen.com</td>\n",
       "      <td>www.macheen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>RTP Holdings</td>\n",
       "      <td>USA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Radnor</td>\n",
       "      <td>saas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>Indoor location services, strategy, solutions....</td>\n",
       "      <td>Indoor GPS makes everyday activities faster, e...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.rtpholdings.com</td>\n",
       "      <td>http://www.linkedin.com/company/rtp-holdings</td>\n",
       "      <td>rtpholdings.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>rtpholdings</td>\n",
       "      <td>http://www.rtpholdings.com</td>\n",
       "      <td>RTP Holdings - RTP Holdings Home Solution Bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>SeatServe</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "      <td>e-commerce|mobile|sports</td>\n",
       "      <td>commerce and shopping|mobile|sports</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>A real-time delivery SaaS solution designed fo...</td>\n",
       "      <td>SeatServe is a digital solutions provider base...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://seatserve.com</td>\n",
       "      <td>https://www.linkedin.com/company/seatserve</td>\n",
       "      <td>seatserve.com</td>\n",
       "      <td>info@seatserve.com</td>\n",
       "      <td>0</td>\n",
       "      <td>seatserve</td>\n",
       "      <td>http://seatserve.com</td>\n",
       "      <td>SeatServe - Stay Seated. In-Seat Delivery at Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               li_cpy_name country_code state_code         region  \\\n",
       "1888               NuORDER          USA         CA    Los Angeles   \n",
       "1889  EvoNexus (CommNexus)          USA         CA      San Diego   \n",
       "1890           Macheen Inc          USA         TX         Austin   \n",
       "1891          RTP Holdings          USA         PA   Philadelphia   \n",
       "1892             SeatServe          USA         NY  New York City   \n",
       "\n",
       "                city                                      category_list  \\\n",
       "1888  West Hollywood     b2b|e-commerce|fashion|internet|saas|wholesale   \n",
       "1889        La Jolla  big data|cyber security|hardware|life science|...   \n",
       "1890          Austin                  enterprise software|internet|saas   \n",
       "1891          Radnor                                               saas   \n",
       "1892        New York                           e-commerce|mobile|sports   \n",
       "\n",
       "                                    category_group_list   industry  \\\n",
       "1888     commerce and shopping|design|internet services  Wholesale   \n",
       "1889  biotechnology|data and analytics|hardware|info...   Wireless   \n",
       "1890                         internet services|software   Wireless   \n",
       "1891                                                NaN   Wireless   \n",
       "1892                commerce and shopping|mobile|sports   Wireless   \n",
       "\n",
       "                                      short_description  \\\n",
       "1888  NuORDER is a cloud & mobile B2B eCommerce plat...   \n",
       "1889  EvoNexus is a non-profit technology incubator ...   \n",
       "1890  Macheen is a SaaS-based platform that brings m...   \n",
       "1891  Indoor location services, strategy, solutions....   \n",
       "1892  A real-time delivery SaaS solution designed fo...   \n",
       "\n",
       "                                            description  \\\n",
       "1888  NuORDER empowers B2B eCommerce sites for over ...   \n",
       "1889  EvoNexus (formerly CommNexus, formerly the Tel...   \n",
       "1890  Macheen, Inc is a SaaS company that brings mob...   \n",
       "1891  Indoor GPS makes everyday activities faster, e...   \n",
       "1892  SeatServe is a digital solutions provider base...   \n",
       "\n",
       "                            ...                         funding_total_usd  \\\n",
       "1888                        ...                                13900000.0   \n",
       "1889                        ...                                       NaN   \n",
       "1890                        ...                                34394995.0   \n",
       "1891                        ...                                       NaN   \n",
       "1892                        ...                                       NaN   \n",
       "\n",
       "          last_funding_on                homepage_url  \\\n",
       "1888  2015-02-01 00:00:00      http://www.nuorder.com   \n",
       "1889                  NaN     http://www.evonexus.org   \n",
       "1890  2013-12-01 00:00:00          http://macheen.com   \n",
       "1891                  NaN  http://www.rtpholdings.com   \n",
       "1892                  NaN        http://seatserve.com   \n",
       "\n",
       "                                      linkedin_url           domain  \\\n",
       "1888       http://www.linkedin.com/company/2779405      nuorder.com   \n",
       "1889     http://www.linkedin.com/company/commnexus     evonexus.org   \n",
       "1890  https://www.linkedin.com/company/macheen-inc      macheen.com   \n",
       "1891  http://www.linkedin.com/company/rtp-holdings  rtpholdings.com   \n",
       "1892    https://www.linkedin.com/company/seatserve    seatserve.com   \n",
       "\n",
       "                   email enterprise_software_present domain_cleaned  \\\n",
       "1888    info@nuorder.com                           0        nuorder   \n",
       "1889                 NaN                           0       evonexus   \n",
       "1890    info@macheen.com                           1        macheen   \n",
       "1891                 NaN                           0    rtpholdings   \n",
       "1892  info@seatserve.com                           0      seatserve   \n",
       "\n",
       "                         website  \\\n",
       "1888      http://www.nuorder.com   \n",
       "1889     http://www.evonexus.org   \n",
       "1890          http://macheen.com   \n",
       "1891  http://www.rtpholdings.com   \n",
       "1892        http://seatserve.com   \n",
       "\n",
       "                                           website_text  \n",
       "1888  NuORDER #1 B2B eCommerce Solution BRANDS RETAI...  \n",
       "1889  EvoNexus Jobs Contact Us Resources About About...  \n",
       "1890                                    www.macheen.com  \n",
       "1891  RTP Holdings - RTP Holdings Home Solution Bene...  \n",
       "1892  SeatServe - Stay Seated. In-Seat Delivery at Y...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cotraining test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sklearn_cotraining.classifiers' from 'sklearn_cotraining/classifiers.pyc'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn_cotraining.classifiers import CoTrainingClassifier\n",
    "import sklearn_cotraining.classifiers\n",
    "reload(sklearn_cotraining.classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1506, 1199), (1506, 7435))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "np.random.seed(5)\n",
    "msk = np.random.rand(len(df_final)) < 0.8\n",
    "train = df_final[msk]\n",
    "test = df_final[~msk]\n",
    "train.index = range(len(train))\n",
    "test.index = range(len(test))\n",
    "\n",
    "tfidf_vectorizer_descr = TfidfVectorizer(max_df=0.8, min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "X_descr_train = tfidf_vectorizer_descr.fit_transform(train['description'].fillna(''))\n",
    "X_descr_test = tfidf_vectorizer_descr.transform(test['description'].fillna(''))\n",
    "\n",
    "tfidf_vectorizer_website_text = TfidfVectorizer(max_df=0.8, min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "X_website_text_train = tfidf_vectorizer_website_text.fit_transform(train['website_text'].fillna(''))\n",
    "X_website_text_test = tfidf_vectorizer_website_text.transform(test['website_text'].fillna(''))\n",
    "\n",
    "X_descr_train.shape,X_website_text_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70% unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1117\n",
       "1     389\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_final[msk]\n",
    "test = df_final[~msk]\n",
    "train.index = range(len(train))\n",
    "test.index = range(len(test))\n",
    "y_train,y_test = train['enterprise_software_present'],test['enterprise_software_present']\n",
    "y_train_copy = y_train.copy()\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    1051\n",
       " 0     335\n",
       " 1     120\n",
       "Name: enterprise_software_present, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting random 70% y_train as -1 (unlabelled)\n",
    "np.random.seed(5)\n",
    "msk1 = np.random.rand(len(y_train)) < 0.7\n",
    "y_train[msk1] = -1\n",
    "X_train_labelled = hstack([X_descr_train[~msk1,:],X_website_text_train[~msk1,:]])\n",
    "y_train_labelled = y_train[~msk1]\n",
    "X_test = hstack([X_descr_test,X_website_text_test])\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "    training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99       335\n",
      "          1       0.94      1.00      0.97       120\n",
      "\n",
      "avg / total       0.98      0.98      0.98       455\n",
      "\n",
      "    training set unlabelled\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.82      0.79       782\n",
      "          1       0.34      0.26      0.30       269\n",
      "\n",
      "avg / total       0.66      0.68      0.67      1051\n",
      "\n",
      "    testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.84      0.82       302\n",
      "          1       0.35      0.31      0.33        85\n",
      "\n",
      "avg / total       0.71      0.72      0.71       387\n",
      "\n",
      "\n",
      "\n",
      "Logistic CoTraining\n",
      "no of iterations took for fitting:160\n",
      "    training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.82      0.86       335\n",
      "          1       0.61      0.77      0.68       120\n",
      "\n",
      "avg / total       0.83      0.81      0.81       455\n",
      "\n",
      "    training set unlabelled\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.73      0.75       782\n",
      "          1       0.31      0.36      0.34       269\n",
      "\n",
      "avg / total       0.65      0.63      0.64      1051\n",
      "\n",
      "    testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.75      0.78       302\n",
      "          1       0.30      0.38      0.33        85\n",
      "\n",
      "avg / total       0.70      0.67      0.68       387\n",
      "\n",
      "\n",
      "\n",
      "naive bayes\n",
      "    training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.87       335\n",
      "          1       1.00      0.13      0.24       120\n",
      "\n",
      "avg / total       0.83      0.77      0.70       455\n",
      "\n",
      "    training set unlabelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85       782\n",
      "          1       0.33      0.00      0.01       269\n",
      "\n",
      "avg / total       0.64      0.74      0.64      1051\n",
      "\n",
      "    testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.99      0.87       302\n",
      "          1       0.25      0.01      0.02        85\n",
      "\n",
      "avg / total       0.66      0.78      0.69       387\n",
      "\n",
      "\n",
      "\n",
      "naive bayes cotraining\n",
      "no of iterations took for fitting:173\n",
      "    training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.84      0.83       335\n",
      "          1       0.52      0.47      0.49       120\n",
      "\n",
      "avg / total       0.74      0.75      0.74       455\n",
      "\n",
      "    training set unlabelled\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.80      0.78       782\n",
      "          1       0.33      0.29      0.31       269\n",
      "\n",
      "avg / total       0.65      0.67      0.66      1051\n",
      "\n",
      "    testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.79      0.79       302\n",
      "          1       0.26      0.26      0.26        85\n",
      "\n",
      "avg / total       0.67      0.67      0.67       387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic'\n",
    "base_lr = LogisticRegression(class_weight='balanced')\n",
    "base_lr.fit(X_train_labelled, y_train_labelled)\n",
    "print('    training set')\n",
    "y_pred = base_lr.predict(X_train_labelled)\n",
    "print classification_report(y_train[~msk1], y_pred)\n",
    "print('    training set unlabelled')\n",
    "y_pred = base_lr.predict(hstack([X_descr_train[msk1,:],X_website_text_train[msk1,:]]))\n",
    "print classification_report(y_train_copy[msk1], y_pred)\n",
    "print('    testing set')\n",
    "y_pred = base_lr.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\n\\nLogistic CoTraining'\n",
    "lg_co_clf = sklearn_cotraining.classifiers.CoTrainingClassifier(LogisticRegression(class_weight='balanced'), \n",
    "                                                                u=len(y_train)//10,k=1000)\n",
    "lg_co_clf.fit(X_website_text_train, X_descr_train, y_train)\n",
    "print('    training set')\n",
    "y_pred = lg_co_clf.predict(X_website_text_train[~msk1,:], X_descr_train[~msk1,:])\n",
    "print classification_report(y_train_copy[~msk1], y_pred)\n",
    "print('    training set unlabelled')\n",
    "y_pred = lg_co_clf.predict(X_website_text_train[msk1,:], X_descr_train[msk1,:])\n",
    "print classification_report(y_train_copy[msk1], y_pred)\n",
    "print('    testing set')\n",
    "y_pred = lg_co_clf.predict(X_website_text_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\n\\nnaive bayes'\n",
    "clf = MultinomialNB(fit_prior=False)\n",
    "clf.fit(X_train_labelled, y_train_labelled)\n",
    "print('    training set')\n",
    "y_pred = clf.predict(X_train_labelled)\n",
    "print classification_report(y_train[~msk1], y_pred)\n",
    "print('    training set unlabelled')\n",
    "y_pred = clf.predict(hstack([X_descr_train[msk1,:],X_website_text_train[msk1,:]]))\n",
    "print classification_report(y_train_copy[msk1], y_pred)\n",
    "print('    testing set')\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\n\\nnaive bayes cotraining'\n",
    "clf = sklearn_cotraining.classifiers.CoTrainingClassifier(MultinomialNB(fit_prior=False), \n",
    "                                                                u=len(y_train)//10,k=1000)\n",
    "clf.fit(X_website_text_train, X_descr_train, y_train)\n",
    "print('    training set')\n",
    "y_pred = clf.predict(X_website_text_train[~msk1,:], X_descr_train[~msk1,:])\n",
    "print classification_report(y_train_copy[~msk1], y_pred)\n",
    "print('    training set unlabelled')\n",
    "y_pred = clf.predict(X_website_text_train[msk1,:], X_descr_train[msk1,:])\n",
    "print classification_report(y_train_copy[msk1], y_pred)\n",
    "print('    testing set')\n",
    "y_pred = clf.predict(X_website_text_test, X_descr_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic website train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.93      1117\n",
      "          1       0.75      0.91      0.82       389\n",
      "\n",
      "avg / total       0.91      0.90      0.90      1506\n",
      "\n",
      "Logistic website test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.77      0.79       302\n",
      "          1       0.30      0.34      0.32        85\n",
      "\n",
      "avg / total       0.69      0.68      0.68       387\n",
      "\n",
      "\n",
      "\n",
      "Logistic description train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.84      0.89      1117\n",
      "          1       0.65      0.85      0.74       389\n",
      "\n",
      "avg / total       0.87      0.85      0.85      1506\n",
      "\n",
      "Logistic description test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.73      0.77       302\n",
      "          1       0.31      0.42      0.36        85\n",
      "\n",
      "avg / total       0.71      0.66      0.68       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic website train'\n",
    "base_lr = LogisticRegression(class_weight='balanced')\n",
    "base_lr.fit(X_website_text_train, y_train_copy)\n",
    "y_pred = base_lr.predict(X_website_text_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'Logistic website test'\n",
    "y_pred = base_lr.predict(X_website_text_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\n\\nLogistic description train'\n",
    "base_lr = LogisticRegression(class_weight='balanced')\n",
    "base_lr.fit(X_descr_train, y_train_copy)\n",
    "y_pred = base_lr.predict(X_descr_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'Logistic description test'\n",
    "y_pred = base_lr.predict(X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm website train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.78      0.85      1117\n",
      "          1       0.57      0.82      0.67       389\n",
      "\n",
      "avg / total       0.83      0.79      0.80      1506\n",
      "\n",
      "svm website test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.63      0.70       302\n",
      "          1       0.23      0.40      0.29        85\n",
      "\n",
      "avg / total       0.67      0.58      0.61       387\n",
      "\n",
      "\n",
      "\n",
      "svm description train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.64      0.72      1117\n",
      "          1       0.38      0.64      0.48       389\n",
      "\n",
      "avg / total       0.72      0.64      0.66      1506\n",
      "\n",
      "svm description test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.62      0.71       302\n",
      "          1       0.29      0.55      0.38        85\n",
      "\n",
      "avg / total       0.71      0.60      0.64       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'svm website train'\n",
    "base_svm = SVC(kernel='linear',class_weight='balanced')\n",
    "base_svm.fit(X_website_text_train, y_train_copy)\n",
    "y_pred = base_svm.predict(X_website_text_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'svm website test'\n",
    "y_pred = base_svm.predict(X_website_text_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\n\\nsvm description train'\n",
    "base_svm = SVC(kernel='linear',class_weight='balanced')\n",
    "base_svm.fit(X_descr_train, y_train_copy)\n",
    "y_pred = base_svm.predict(X_descr_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'svm description test'\n",
    "y_pred = base_svm.predict(X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes website train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.83      1117\n",
      "          1       0.53      0.62      0.58       389\n",
      "\n",
      "avg / total       0.78      0.76      0.77      1506\n",
      "\n",
      "naive bayes website test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.72      0.76       302\n",
      "          1       0.29      0.41      0.34        85\n",
      "\n",
      "avg / total       0.70      0.65      0.67       387\n",
      "\n",
      "\n",
      "\n",
      "naive bayes description train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.82      0.86      1117\n",
      "          1       0.60      0.76      0.67       389\n",
      "\n",
      "avg / total       0.83      0.81      0.81      1506\n",
      "\n",
      "naive bayes description test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.71      0.75       302\n",
      "          1       0.28      0.40      0.33        85\n",
      "\n",
      "avg / total       0.69      0.64      0.66       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'naive bayes website train'\n",
    "clf = MultinomialNB(fit_prior=False)\n",
    "clf.fit(X_website_text_train, y_train_copy)\n",
    "y_pred = clf.predict(X_website_text_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'naive bayes website test'\n",
    "y_pred = clf.predict(X_website_text_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\n\\nnaive bayes description train'\n",
    "clf = MultinomialNB(fit_prior=False)\n",
    "clf.fit(X_descr_train, y_train_copy)\n",
    "y_pred = clf.predict(X_descr_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'naive bayes description test'\n",
    "y_pred = clf.predict(X_descr_test)\n",
    "print classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural_network website train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99      1117\n",
      "          1       0.95      0.99      0.97       389\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1506\n",
      "\n",
      "neural_network website test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.84      0.81       302\n",
      "          1       0.25      0.19      0.22        85\n",
      "\n",
      "avg / total       0.67      0.70      0.68       387\n",
      "\n",
      "\n",
      "\n",
      "neural_network description train\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97      1117\n",
      "          1       1.00      0.79      0.88       389\n",
      "\n",
      "avg / total       0.95      0.95      0.94      1506\n",
      "\n",
      "neural_network description test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.72      0.75       302\n",
      "          1       0.23      0.31      0.27        85\n",
      "\n",
      "avg / total       0.66      0.63      0.64       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler(with_mean=False)  \n",
    "scaler.fit(X_website_text_train)\n",
    "X_website_text_train = scaler.transform(X_website_text_train)\n",
    "X_website_text_test = scaler.transform(X_website_text_test)\n",
    "print 'neural_network website train'\n",
    "clf = MLPClassifier(hidden_layer_sizes=(2),alpha=0.3)\n",
    "clf.fit(X_website_text_train, y_train_copy)\n",
    "y_pred = clf.predict(X_website_text_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'neural_network website test'\n",
    "y_pred = clf.predict(X_website_text_test)\n",
    "print classification_report(y_test, y_pred)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  \n",
    "scaler.fit(X_descr_train)\n",
    "X_descr_train = scaler.transform(X_descr_train)\n",
    "X_descr_test = scaler.transform(X_descr_test)\n",
    "print '\\n\\nneural_network description train'\n",
    "clf = MLPClassifier(hidden_layer_sizes=(2),alpha=0.3)\n",
    "clf.fit(X_descr_train, y_train_copy)\n",
    "y_pred = clf.predict(X_descr_train)\n",
    "print classification_report(y_train_copy, y_pred)\n",
    "print 'neural_network description test'\n",
    "y_pred = clf.predict(X_descr_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1506,), (1506, 7435), (1506, 1199))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_copy.shape,X_website_text_train.shape,X_descr_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
